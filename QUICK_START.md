# Quick Start Guide - CHU Data Lakehouse

## üöÄ D√©marrage Rapide

### 1. D√©marrer l'Infrastructure

```bash
cd "C:\Users\littl\Desktop\Big DATA\projet_git"
docker-compose up -d
```

**Attendre 2-3 minutes** que tous les services d√©marrent.

### 2. V√©rifier les Services

```bash
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep chu_
```

Tous les services doivent √™tre `Up` ou `Up (healthy)`.

### 3. Acc√®s aux Interfaces

| Service | URL | Login | Password |
|---------|-----|-------|----------|
| **Airflow** | http://localhost:8080 | admin | admin123 |
| **Jupyter Lab** | http://localhost:8888 | - | admin123 (token) |
| **Superset** | http://localhost:8088 | admin | admin123 |
| **MinIO Console** | http://localhost:9001 | minioadmin | minioadmin123 |
| **PgAdmin** | http://localhost:5050 | admin@chu.fr | admin123 |
| **Spark Master UI** | http://localhost:8081 | - | - |

## üìä Ex√©cuter le Pipeline ETL

### Option A: Pipeline Complet (Recommand√© pour Production)

1. Aller sur http://localhost:8080
2. Login avec `admin` / `admin123`
3. Cliquer sur le DAG `chu_pipeline_pyspark_jobs`
4. Cliquer sur le bouton ‚ñ∂Ô∏è (Play) en haut √† droite
5. Confirmer avec "Trigger DAG"

**Dur√©e**: ~3-5 minutes

**Ce qui est ex√©cut√©**:
- Bronze: Extraction de toutes les sources
- Silver: Nettoyage et anonymisation
- Gold: Construction du star schema
- Benchmarks: Tests de performance

### Option B: Pipeline Granulaire (Recommand√© pour Dev/Debug)

1. Aller sur http://localhost:8080
2. Login avec `admin` / `admin123`
3. Cliquer sur le DAG `chu_pipeline_split`
4. Cliquer sur le bouton ‚ñ∂Ô∏è (Play)

**Avantages**:
- Chaque t√¢che s'ex√©cute individuellement
- Retry cibl√© en cas d'erreur
- Parall√©lisation maximale
- Monitoring pr√©cis

### Option C: Notebooks Jupyter (Recommand√© pour Exploration)

1. Aller sur http://localhost:8888
2. Token: `admin123`
3. Ouvrir le r√©pertoire `notebooks/`
4. Ex√©cuter les notebooks dans l'ordre:
   - `01_Extract_Bronze_SOURCES_DIRECTES.ipynb`
   - `02_Transform_Silver_NETTOYAGE.ipynb`
   - `03_Transform_Gold_STAR_SCHEMA.ipynb`
   - `04_Performance_Benchmarks_CLEAN.ipynb`
   - `06_Export_Gold_to_PostgreSQL.ipynb`

## üîç Monitoring

### V√©rifier l'√âtat des Jobs Airflow

```bash
# Liste des DAGs
docker exec chu_airflow_webserver airflow dags list

# √âtat d'un run sp√©cifique
docker exec chu_airflow_webserver airflow dags list-runs -d chu_pipeline_pyspark_jobs
```

### Logs en Temps R√©el

```bash
# Logs Spark Worker
docker logs -f chu_spark_worker

# Logs Airflow Scheduler
docker logs -f chu_airflow_scheduler

# Logs Jupyter
docker logs -f chu_jupyter
```

### V√©rifier les Donn√©es

```bash
# Bronze
docker exec chu_jupyter bash -c "ls -lh /home/jovyan/data/bronze/{postgres,csv}/"

# Silver
docker exec chu_jupyter bash -c "ls -lh /home/jovyan/data/silver/"

# Gold
docker exec chu_jupyter bash -c "ls -lh /home/jovyan/data/gold/"
```

## üêõ Troubleshooting

### Erreur: Python version mismatch

**Sympt√¥me**: `RuntimeError: Python in worker has different version 3.8 than that in driver 3.11`

**Solution**: Les DAGs ont d√©j√† √©t√© corrig√©s avec les variables `PYSPARK_PYTHON` et `PYSPARK_DRIVER_PYTHON`.

Si le probl√®me persiste:
```bash
docker-compose restart airflow-scheduler airflow-webserver
```

### Erreur: Permission denied

**Sympt√¥me**: `Unable to clear output directory` ou `Permission denied`

**Solution**:
```bash
docker exec -u root chu_jupyter bash -c "chown -R jovyan:users /home/jovyan/data"
```

### Erreur: Spark Worker en restart loop

**Sympt√¥me**: Container `chu_spark_worker` red√©marre continuellement

**Solution**: V√©rifier les logs:
```bash
docker logs --tail 50 chu_spark_worker
```

Le hostname est correct (`chu-spark-master`). Si probl√®me persiste:
```bash
docker-compose restart spark-worker
```

### Erreur: Fichier manquant (PATH_NOT_FOUND)

**Sympt√¥me**: `Path does not exist: file:/home/jovyan/data/bronze/csv/departements`

**Solution**: Le fichier a d√©j√† √©t√© extrait. V√©rifier:
```bash
docker exec chu_jupyter bash -c "ls -la /home/jovyan/data/bronze/csv/"
```

Si manquant, r√©ex√©cuter le notebook 01 ou extraire manuellement.

### Nettoyer et Recommencer

Si vous voulez un fresh start complet:

```bash
# Arr√™ter tous les services
docker-compose down

# Nettoyer les donn√©es (ATTENTION: supprime toutes les donn√©es!)
docker exec -u root chu_jupyter bash -c "rm -rf /home/jovyan/data/bronze/* /home/jovyan/data/silver/* /home/jovyan/data/gold/*"

# Red√©marrer
docker-compose up -d
```

## üìà Visualiser les R√©sultats

### Option 1: Superset (BI)

1. Aller sur http://localhost:8088
2. Login: `admin` / `admin123`
3. Settings ‚Üí Database Connections ‚Üí + DATABASE
4. S√©lectionner "PostgreSQL"
5. SQLAlchemy URI:
   ```
   postgresql://admin:admin123@chu_postgres:5432/healthcare_data
   ```
6. Advanced ‚Üí SQL Lab: Cocher "Expose database in SQL Lab"
7. Test Connection ‚Üí CONNECT
8. SQL Lab ‚Üí s√©lectionner schema `gold`

### Option 2: PgAdmin

1. Aller sur http://localhost:5050
2. Login: `admin@chu.fr` / `admin123`
3. Add Server:
   - Name: CHU Healthcare
   - Host: chu_postgres
   - Port: 5432
   - Database: healthcare_data
   - Username: admin
   - Password: admin123

### Option 3: Jupyter Notebooks

Ouvrir `06_Export_Gold_to_PostgreSQL.ipynb` pour voir les requ√™tes SQL exemples.

## üìä Donn√©es Disponibles

### Bronze Layer (Donn√©es Brutes)
- **PostgreSQL**: 13 tables (Patient, Consultation, Diagnostic, etc.)
- **CSV**: 4 fichiers (√©tablissements, satisfaction, d√©c√®s 2019, d√©partements)
- **Total**: ~4M lignes

### Silver Layer (Nettoy√© + Anonymis√©)
- Patient (anonymis√© SHA-256)
- Consultation (dates standardis√©es)
- √âtablissements (enrichis)
- Satisfaction 2019
- D√©c√®s 2019
- Tables de r√©f√©rence

### Gold Layer (Star Schema)
**Dimensions**:
- dim_temps (4,748 jours: 2013-2025)
- dim_patient
- dim_diagnostic
- dim_professionnel
- dim_etablissement

**Faits**:
- fait_consultation (1M+ consultations)
- fait_hospitalisation (82K hospitalisations)
- fait_deces (620K d√©c√®s 2019)
- fait_satisfaction (8 √©valuations 2019)

## üîß Configuration

### M√©moire Spark (32G RAM disponible)
- Driver Memory: 8G
- Executor Memory: 8G
- Worker Cores: 2

Pour modifier:
1. √âditer [docker-compose.yml](docker-compose.yml) (ligne 150)
2. √âditer les DAGs: [chu_pipeline_split.py](airflow/dags/chu_pipeline_split.py), [pipeline_pyspark_jobs.py](airflow/dags/pipeline_pyspark_jobs.py)
3. Red√©marrer: `docker-compose restart spark-worker airflow-scheduler`

## üìö Documentation Compl√®te

- [CONFIGURATION_FINALE.md](CONFIGURATION_FINALE.md) - Configuration d√©taill√©e
- [CORRECTIONS_FINALES.md](CORRECTIONS_FINALES.md) - Probl√®mes r√©solus
- [spark/jobs/README.md](spark/jobs/README.md) - Structure jobs modulaires

## üÜò Support

En cas de probl√®me:
1. V√©rifier les logs du container concern√©
2. Consulter [CORRECTIONS_FINALES.md](CORRECTIONS_FINALES.md)
3. Red√©marrer le service: `docker-compose restart <service_name>`
4. Fresh start complet si n√©cessaire

---

**Projet**: CHU Data Lakehouse
**Auteurs**: Nejma MOUALHI | Brieuc OLIVIERI | Nicolas TAING
**Version**: 2.1
**Date**: 24 octobre 2025
