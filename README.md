# ğŸ¥ CHU Data Lakehouse - Projet Big Data

**Cloud Healthcare Unit - Delta Lake Architecture**

CESI FISA A4 - Livrable 2

## ğŸ‘¥ Ã‰quipe

- **Nejma MOUALHI**
- **Brieuc OLIVIERI**
- **Nicolas TAING**

---

## âš¡ STATUT : LIVRABLE 2 COMPLET ET OPÃ‰RATIONNEL âœ…

**ğŸ‰ Pipeline 100% fonctionnel - Bronze â†’ Silver â†’ Gold + Superset**

### ğŸ“š Documentation Essentielle

**Tous les guides sont dans le dossier [`docs/`](docs/)**:

- ğŸš€ **[GUIDE_UTILISATION.md](docs/GUIDE_UTILISATION.md)** - Guide complet d'utilisation (dÃ©marrage, notebooks, Superset, SQL, Docker)
- ğŸ“Š **[SYNTHESE_PROJET.md](docs/SYNTHESE_PROJET.md)** - SynthÃ¨se technique complÃ¨te (architecture, dÃ©couvertes, conformitÃ©)
- ğŸ”§ **[TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)** - Solutions aux problÃ¨mes courants
- ğŸ“‹ **[docs/README.md](docs/README.md)** - Index de la documentation

**Ancienne documentation** : ArchivÃ©e dans [`docs/archives/`](docs/archives/) pour rÃ©fÃ©rence

### ğŸ“Š RÃ©sultats Finaux

**Architecture MÃ©daillon ComplÃ¨te**:

| Layer | Tables | Lignes | Temps | Statut |
|-------|--------|--------|-------|--------|
| **Bronze** | 17 | ~4M | ~2 min | âœ… |
| **Silver** | 13 | ~3.5M | ~3 min | âœ… |
| **Gold** | 9 (5 dims + 4 faits) | ~2.9M | ~3 min | âœ… |
| **PostgreSQL** | 9 tables gold | ~2.9M | ~3 min | âœ… |

**Tables de Faits (Conforme Livrable 1)** âœ…:
1. **fait_consultation** - 1,027,157 consultations (2015-2023)
2. **fait_hospitalisation** - 82,216 hospitalisations (2013-2025) â† DÃ©couvert!
3. **fait_deces** - 620,625 dÃ©cÃ¨s (2019 filtrÃ©)
4. **fait_satisfaction** - 8 scores E-Satis (2019)

**Dimensions** (5):
- dim_temps, dim_patient, dim_diagnostic, dim_professionnel, dim_etablissement

### ğŸš€ Quick Start (3 Ã©tapes)

```bash
# 1. DÃ©marrer la stack
docker-compose up -d

# 2. AccÃ©der Jupyter: http://localhost:8888

# 3. ExÃ©cuter notebooks dans l'ordre:
#    01_Extract_Bronze_SOURCES_DIRECTES.ipynb      (~2 min)
#    02_Transform_Silver_NETTOYAGE.ipynb           (~3 min)
#    03_Transform_Gold_STAR_SCHEMA.ipynb           (~3 min)
#    06_Export_Gold_to_PostgreSQL.ipynb            (~3 min)

# 4. AccÃ©der Superset: http://localhost:8088 (admin/admin123)
```

**Temps total pipeline**: ~11 minutes â±ï¸

### âœ… Architecture ETLT (Conforme Livrable 1)

```
PostgreSQL + CSV â†’ Bronze â†’ Silver (Pseudonymisation) â†’ Gold (Star Schema) â†’ PostgreSQL â†’ Superset
```

- âœ… **Extract**: PostgreSQL (13 tables) + CSV (4 fichiers)
- âœ… **Transform 1**: Pseudonymisation RGPD (SHA-256 + sel)
- âœ… **Load**: Parquet compressÃ© (snappy) + partitionnement
- âœ… **Transform 2**: Star Schema (5 dimensions + 4 faits)
- âœ… **Visualisation**: Apache Superset + PostgreSQL Gold

---

## ğŸš€ Quick Start (3 Ã©tapes)

### 1. Clone le projet

```bash
git clone <votre-repo-url>
cd projet_git
```

### 2. Lance la stack complÃ¨te

```bash
docker-compose up --build -d
```

**Attends 2-3 minutes** que tous les services dÃ©marrent.

### 3. VÃ©rifie que tout fonctionne

```bash
docker-compose ps
```

Tous les services doivent Ãªtre **Up** (sauf worker Spark - non utilisÃ©).

---

## ğŸŒ Services et AccÃ¨s

| Service | URL | Login | Mot de passe | RÃ´le |
|---------|-----|-------|--------------|------|
| **Airflow** | http://localhost:8080 | admin | admin123 | Orchestration ETL |
| **Jupyter Lab** | http://localhost:8888 | - | token: admin123 | DÃ©veloppement PySpark |
| **MinIO Console** | http://localhost:9001 | minioadmin | minioadmin123 | Stockage S3 (Delta Lake) |
| **Spark Master UI** | http://localhost:8081 | - | - | Monitoring Spark |
| **Superset** | http://localhost:8088 | admin | admin123 | Visualisation BI |
| **pgAdmin** | http://localhost:5050 | admin@chu.fr | admin123 | Admin PostgreSQL |
| **PostgreSQL** | localhost:5432 | admin | admin123 | Base de donnÃ©es source |

---

## ğŸ“ Architecture Delta Lake

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DATA LAKEHOUSE CHU - DELTA LAKE             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  PostgreSQL (sources) â”€â”€â”                                   â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                    â”‚ Airflow â”‚  (Orchestration ETL)         â”‚
â”‚                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                              â”‚
â”‚                         â”‚                                   â”‚
â”‚                         â–¼                                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚            â”‚   MinIO S3 (Delta Lake)    â”‚                   â”‚
â”‚            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚            â”‚  ğŸ“¦ lakehouse/             â”‚                   â”‚
â”‚            â”‚    â”œâ”€ bronze/  (raw)       â”‚                   â”‚
â”‚            â”‚    â”œâ”€ silver/  (T1 RGPD)   â”‚                   â”‚
â”‚            â”‚    â””â”€ gold/    (T2 DWH)    â”‚                   â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                         â”‚                                   â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚        â–¼                                  â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Jupyter Lab  â”‚                  â”‚ Supersetâ”‚             â”‚
â”‚  â”‚  + PySpark   â”‚                  â”‚   BI    â”‚             â”‚
â”‚  â”‚ (Analytics)  â”‚                  â”‚(Dashbds)â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—„ï¸ DonnÃ©es de DÃ©part

### âš ï¸ IMPORTANT : Restauration du dump PostgreSQL

**AprÃ¨s le premier lancement**, vous devez restaurer le dump de la base de donnÃ©es :

```bash
# 1. Lancer la stack
docker-compose up -d

# 2. Attendre que PostgreSQL soit prÃªt (2-3 minutes)

# 3. Restaurer le dump
docker exec -it chu_postgres pg_restore -U admin -d healthcare_data -v /docker-entrypoint-initdb.d/DATA2023.dump
```

Le dump contient toutes les **donnÃ©es rÃ©elles du CHU** (patients, consultations, diagnostics, etc.)

ğŸ“– **Voir [data/README.md](data/README.md) pour les instructions dÃ©taillÃ©es.**

---

## ğŸ¯ Workflow Livrable 2

### Ã‰tape 1 : DÃ©velopper dans Jupyter Lab

1. Ouvre **Jupyter Lab** : http://localhost:8888 (token: `admin123`)
2. CrÃ©e un nouveau notebook dans `notebooks/`
3. Utilise PySpark avec Delta Lake :

```python
from pyspark.sql import SparkSession
from delta import *

# Session Spark avec Delta Lake
builder = SparkSession.builder.appName("CHU ETL") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
    .config("spark.hadoop.fs.s3a.endpoint", "http://chu_minio:9000") \
    .config("spark.hadoop.fs.s3a.access.key", "minioadmin") \
    .config("spark.hadoop.fs.s3a.secret.key", "minioadmin123") \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem")

spark = configure_spark_with_delta_pip(builder).getOrCreate()

# Lire depuis PostgreSQL
df = spark.read.jdbc(
    url="jdbc:postgresql://chu_postgres:5432/healthcare_data",
    table='"Patient"',
    properties={"user": "admin", "password": "admin123"}
)

# Ã‰crire en Delta Lake (Bronze)
df.write.format("delta").mode("overwrite").save("s3a://lakehouse/bronze/patient")

# Lire depuis Delta Lake
df_delta = spark.read.format("delta").load("s3a://lakehouse/bronze/patient")
df_delta.show(5)
```

### Ã‰tape 2 : CrÃ©er les transformations T1 et T2

**T1 (Bronze â†’ Silver) : RGPD - Pseudonymisation**
- Anonymiser les donnÃ©es PII (SHA-256)
- Calculer l'Ã¢ge Ã  partir de la date de naissance
- Supprimer les colonnes sensibles

**T2 (Silver â†’ Gold) : ModÃ¨le dimensionnel**
- CrÃ©er les dimensions dÃ©normalisÃ©es
- Enrichir les faits avec les dimensions
- Calculer les mÃ©triques agrÃ©gÃ©es

### Ã‰tape 3 : Orchestrer avec Airflow

1. CrÃ©e ton DAG dans `airflow/dags/`
2. Ouvre **Airflow UI** : http://localhost:8080 (admin / admin123)
3. Active ton DAG
4. Trigger manuellement
5. VÃ©rifie les logs d'exÃ©cution

Exemple DAG fourni : `airflow/dags/exemple_delta_lake.py`

### Ã‰tape 4 : VÃ©rifier dans MinIO

1. Ouvre **MinIO Console** : http://localhost:9001 (minioadmin / minioadmin123)
2. Browse `lakehouse/bronze/`, `silver/`, `gold/`
3. VÃ©rifie la prÃ©sence des fichiers Parquet et `_delta_log/`

### Ã‰tape 5 : Visualiser avec Superset

1. Ouvre **Superset** : http://localhost:8088 (admin / admin123)
2. Connecte-toi Ã  PostgreSQL ou aux donnÃ©es Gold
3. CrÃ©e tes dashboards

---

## ğŸ› ï¸ Stack Technique

| Composant | Version | RÃ´le |
|-----------|---------|------|
| **Apache Airflow** | 2.8.1 | Orchestration ETL |
| **Delta Lake** | 2.4.0 | Lakehouse ACID + versioning |
| **Apache Spark** | 3.4.0 | Moteur distribuÃ© |
| **PySpark** | 3.4.0 | API Python Spark |
| **MinIO** | latest | Stockage S3-compatible |
| **PostgreSQL** | 15-alpine | Base source |
| **Jupyter Lab** | latest | DÃ©veloppement |
| **Apache Superset** | latest | Visualisation BI |

---

## ğŸ”§ Commandes Utiles

### Voir les logs d'un service

```bash
docker logs chu_airflow_webserver -f
docker logs chu_jupyter -f
docker logs chu_postgres -f
```

### RedÃ©marrer un service

```bash
docker-compose restart airflow-webserver
docker-compose restart jupyter
```

### ArrÃªter tout

```bash
docker-compose down
```

### Tout supprimer et recommencer (âš ï¸ PERTE DE DONNÃ‰ES)

```bash
docker-compose down -v
docker-compose up --build -d
```

### VÃ©rifier l'Ã©tat des services

```bash
docker-compose ps
```

### ExÃ©cuter une commande SQL dans PostgreSQL

```bash
docker exec -it chu_postgres psql -U admin -d healthcare_data
```

### Tester Delta Lake dans Jupyter

```bash
docker exec -it chu_jupyter python3 -c "from delta import *; print('âœ… Delta Lake OK')"
```

---

## â“ ProblÃ¨mes FrÃ©quents

### Airflow ne dÃ©marre pas

```bash
# VÃ©rifie les logs
docker logs chu_airflow_init

# RedÃ©marre
docker-compose restart airflow-webserver airflow-scheduler
```

### MinIO buckets n'existent pas

Les buckets sont crÃ©Ã©s automatiquement par `chu_minio_setup`.

Si problÃ¨me :
1. Va sur http://localhost:9001
2. CrÃ©Ã© manuellement `lakehouse` et `warehouse`

### Jupyter ne se connecte pas Ã  MinIO

VÃ©rifie le hostname dans ton code :
- âœ… `http://chu_minio:9000` (dans Docker)
- âŒ `http://localhost:9000` (ne marche pas)

### Port dÃ©jÃ  utilisÃ©

Si tu as dÃ©jÃ  des services sur les mÃªmes ports :
1. ArrÃªte les anciens services
2. Ou modifie les ports dans `docker-compose.yml`

### PostgreSQL n'a pas de donnÃ©es

VÃ©rifiez que les scripts SQL sont bien dans `data/` :

```bash
ls data/
# Doit afficher : 01_init_schema.sql  02_seed_data.sql  03_seed_transactions.sql
```

Si vous devez recharger les donnÃ©es :

```bash
# Stopper et supprimer les volumes
docker-compose down -v

# Relancer (rechargera depuis data/)
docker-compose up --build -d
```

---

## ğŸ“š Documentation ComplÃ©mentaire

- **Guide Ã‰quipe** : [GUIDE_EQUIPE.md](GUIDE_EQUIPE.md) - Onboarding complet pas Ã  pas
- **DonnÃ©es** : [data/README.md](data/README.md) - Instructions pour ajouter vos donnÃ©es

---

## âš ï¸ SÃ©curitÃ© et RGPD

### DonnÃ©es sensibles

Ce projet contient des **donnÃ©es PII de patients** (nom, prÃ©nom, NSS, adresse, etc.).

**Important** :
- âœ… Les donnÃ©es sont **fictives** (gÃ©nÃ©rÃ©es pour le projet)
- âš ï¸ Ne jamais utiliser de vraies donnÃ©es patients
- ğŸ”’ Le `.gitignore` empÃªche le commit de fichiers sensibles (CSV, Parquet, volumes Docker)

### Pseudonymisation (T1)

La transformation T1 doit pseudonymiser :
- `nom` â†’ SHA-256
- `prenom` â†’ SHA-256
- `numero_securite_sociale` â†’ SHA-256
- `adresse`, `telephone`, `email` â†’ SupprimÃ©s

**Exemple** :

```python
from pyspark.sql.functions import sha2, concat_ws

df_silver = df_bronze.withColumn(
    "nom_hash", sha2(concat_ws("_", col("nom"), lit("salt_secret")), 256)
).drop("nom", "prenom", "numero_securite_sociale", "adresse", "telephone", "email")
```

---

## âœ… Checklist Livrable 2

- [ ] Stack complÃ¨te opÃ©rationnelle (tous les services UP)
- [ ] Connexion PostgreSQL â†’ Jupyter Lab validÃ©e
- [ ] Ã‰criture en Delta Lake Bronze validÃ©e
- [ ] Transformation T1 (RGPD) implÃ©mentÃ©e
- [ ] Transformation T2 (DWH) implÃ©mentÃ©e
- [ ] DAG Airflow fonctionnel (Bronze â†’ Silver â†’ Gold)
- [ ] DonnÃ©es visibles dans MinIO (3 zones)
- [ ] Dashboard Superset crÃ©Ã©
- [ ] Documentation complÃ©tÃ©e
- [ ] Code versionnÃ© sur Git

---

## ğŸ“ Objectifs PÃ©dagogiques

1. **Data Lakehouse** : Comprendre l'architecture Bronze/Silver/Gold
2. **Delta Lake** : ACID, versioning, time travel
3. **RGPD** : Pseudonymisation et protection des PII
4. **ETL/ELT** : Orchestration avec Airflow
5. **Big Data** : PySpark pour traiter des volumÃ©tries importantes
6. **BI** : Visualisation des donnÃ©es de santÃ©

---

## ğŸ“ Support

En cas de problÃ¨me :
1. VÃ©rifie les logs : `docker logs <container_name>`
2. Consulte la section **ProblÃ¨mes FrÃ©quents**
3. RedÃ©marre le service concernÃ©
4. En dernier recours : `docker-compose down -v && docker-compose up --build -d`

---

**Bon courage pour le Livrable 2 ! ğŸ’ª**
