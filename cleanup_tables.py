#!/usr/bin/env python3
"""
Script de nettoyage du metastore Hive - CHU Data Lakehouse
Usage : ExÃ©cuter dans Jupyter ou en standalone
"""

from pyspark.sql import SparkSession

# CrÃ©er session Spark avec la config qui Ã©vite les conflits
spark = SparkSession.builder \
    .appName("CHU_Cleanup_Metastore") \
    .config("spark.sql.hive.convertMetastoreParquet", "false") \
    .enableHiveSupport() \
    .getOrCreate()

print("=" * 60)
print("ğŸ§¹ NETTOYAGE HIVE METASTORE - CHU Data Lakehouse")
print("=" * 60)

# Liste des tables Ã  nettoyer
tables = [
    "dim_temps",
    "dim_patient",
    "dim_diagnostic",
    "dim_professionnel",
    "dim_etablissement",
    "fait_consultation"
]

print("\nğŸ“‹ Tables Ã  nettoyer :\n")

# Afficher les tables existantes
try:
    existing_tables = spark.sql("SHOW TABLES").collect()
    if existing_tables:
        for row in existing_tables:
            print(f"  - {row.tableName}")
    else:
        print("  (Aucune table trouvÃ©e)")
except Exception as e:
    print(f"  âš ï¸  Impossible de lister les tables : {e}")

print("\nğŸ—‘ï¸  Suppression des tables...\n")

# Supprimer chaque table
for table in tables:
    try:
        spark.sql(f"DROP TABLE IF EXISTS {table}")
        print(f"  âœ… {table} - supprimÃ©e")
    except Exception as e:
        print(f"  âŒ {table} - erreur : {e}")

print("\n" + "=" * 60)
print("âœ… NETTOYAGE TERMINÃ‰")
print("=" * 60)

# VÃ©rifier qu'il ne reste plus de tables
print("\nğŸ“‹ Tables restantes :\n")
try:
    remaining_tables = spark.sql("SHOW TABLES").collect()
    if remaining_tables:
        for row in remaining_tables:
            print(f"  - {row.tableName}")
    else:
        print("  âœ… Aucune table (metastore propre)")
except Exception as e:
    print(f"  âš ï¸  {e}")

print("\n" + "=" * 60)
print("ğŸ¯ PROCHAINE Ã‰TAPE :")
print("   ExÃ©cuter Notebook 05_Setup_Superset.ipynb")
print("   pour recrÃ©er les tables avec le bon schÃ©ma")
print("=" * 60)

spark.stop()
