{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOLD LAYER - Star Schema (Version qui MARCHE)\n",
    "\n",
    "**Mode LOCAL** : Pas de problème Python version cluster\n",
    "\n",
    "**Auteurs** : Nejma MOUALHI | Brieuc OLIVIERI | Nicolas TAING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 3.5.0 started in LOCAL mode\n",
      "Source: /home/jovyan/data/silver\n",
      "Destination: /home/jovyan/data/gold\n"
     ]
    }
   ],
   "source": [
    "# Spark en mode LOCAL (pas de conflit Python!)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CHU_Gold_Star_Schema\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark {spark.version} started in LOCAL mode\")\n",
    "\n",
    "SILVER_BASE = \"/home/jovyan/data/silver\"\n",
    "GOLD_OUTPUT = \"/home/jovyan/data/gold\"\n",
    "\n",
    "print(f\"Source: {SILVER_BASE}\")\n",
    "print(f\"Destination: {GOLD_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: dim_diagnostic\n",
      "Cleaned: dim_etablissement\n",
      "Cleaned: dim_patient\n",
      "Cleaned: dim_professionnel\n",
      "Cleaned: dim_temps\n",
      "Cleaned: fait_consultation\n",
      "Cleaned: fait_deces\n",
      "Cleaned: fait_hospitalisation\n",
      "Cleaned: fait_satisfaction\n",
      "Gold directory ready\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage automatique des permissions Gold (evite les erreurs)\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "GOLD_OUTPUT = \"/home/jovyan/data/gold\"\n",
    "\n",
    "# Supprimer les tables Gold avec mauvaises permissions\n",
    "if os.path.exists(GOLD_OUTPUT):\n",
    "    for table in os.listdir(GOLD_OUTPUT):\n",
    "        table_path = os.path.join(GOLD_OUTPUT, table)\n",
    "        try:\n",
    "            shutil.rmtree(table_path)\n",
    "            print(f\"Cleaned: {table}\")\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied on {table} - will try to overwrite\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning {table}: {e}\")\n",
    "else:\n",
    "    os.makedirs(GOLD_OUTPUT, exist_ok=True)\n",
    "    print(f\"Created: {GOLD_OUTPUT}\")\n",
    "\n",
    "print(\"Gold directory ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIMENSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DIMENSION: dim_temps\n",
      "================================================================================\n",
      "4,748 days created\n",
      "+--------+-------------+-----+----+---------+------------+--------+-----------+-------------------+\n",
      "|id_temps|date_complete|annee|mois|trimestre|jour_semaine|nom_mois|est_weekend|numero_jour_semaine|\n",
      "+--------+-------------+-----+----+---------+------------+--------+-----------+-------------------+\n",
      "|20130101|   2013-01-01| 2013|   1|        1|     Tuesday| January|      false|                  1|\n",
      "|20130102|   2013-01-02| 2013|   1|        1|   Wednesday| January|      false|                  2|\n",
      "|20130103|   2013-01-03| 2013|   1|        1|    Thursday| January|      false|                  3|\n",
      "|20130104|   2013-01-04| 2013|   1|        1|      Friday| January|      false|                  4|\n",
      "|20130105|   2013-01-05| 2013|   1|        1|    Saturday| January|       true|                  5|\n",
      "+--------+-------------+-----+----+---------+------------+--------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Saved: /home/jovyan/data/gold/dim_temps\n"
     ]
    }
   ],
   "source": [
    "# 1. DIM_TEMPS\n",
    "print(\"=\"*80)\n",
    "print(\"DIMENSION: dim_temps\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "dates = []\n",
    "current = datetime(2013, 1, 1)\n",
    "end = datetime(2025, 12, 31)\n",
    "\n",
    "while current <= end:\n",
    "    dates.append((\n",
    "        current.strftime(\"%Y%m%d\"),\n",
    "        current,\n",
    "        current.year,\n",
    "        current.month,\n",
    "        (current.month - 1) // 3 + 1,\n",
    "        current.strftime(\"%A\"),\n",
    "        current.strftime(\"%B\"),\n",
    "        current.weekday() >= 5,\n",
    "        current.weekday()\n",
    "    ))\n",
    "    current += timedelta(days=1)\n",
    "\n",
    "schema_temps = StructType([\n",
    "    StructField(\"id_temps\", StringType(), False),\n",
    "    StructField(\"date_complete\", DateType(), False),\n",
    "    StructField(\"annee\", IntegerType(), False),\n",
    "    StructField(\"mois\", IntegerType(), False),\n",
    "    StructField(\"trimestre\", IntegerType(), False),\n",
    "    StructField(\"jour_semaine\", StringType(), True),\n",
    "    StructField(\"nom_mois\", StringType(), True),\n",
    "    StructField(\"est_weekend\", BooleanType(), True),\n",
    "    StructField(\"numero_jour_semaine\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "dim_temps = spark.createDataFrame(dates, schema=schema_temps)\n",
    "print(f\"{dim_temps.count():,} days created\")\n",
    "dim_temps.show(5)\n",
    "\n",
    "dim_temps.write.mode(\"overwrite\").parquet(f\"{GOLD_OUTPUT}/dim_temps\")\n",
    "print(f\"Saved: {GOLD_OUTPUT}/dim_temps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIMENSION: dim_patient\n",
      "================================================================================\n",
      "100,000 patients\n",
      "+----------+----------------------------------------------------------------+----------------------------------------------------------------+------+---+--------------+--------------------+-----------+----+--------------+\n",
      "|id_patient|nom_hash                                                        |prenom_hash                                                     |sexe  |age|date_naissance|ville               |code_postal|pays|groupe_sanguin|\n",
      "+----------+----------------------------------------------------------------+----------------------------------------------------------------+------+---+--------------+--------------------+-----------+----+--------------+\n",
      "|5         |d34db878e3724987c7853288b3744ddba9620358185f8b65822014cd45a855ab|d888938a8847ae08380fefffd5d72ae0e3483ed5d312f06b4b259817d15d75d0|male  |55 |1965-10-04    |LES LILAS           |93260      |FR  |O+            |\n",
      "|15        |7c4732648c9b5c5c5e83cc2b6d2f7e628d369593e45e37caf95d3f662082f6d3|c4cf057b68f2fda02383c7d4e90f7aa890e6a9ae232c5fd97d736a1b43e859d4|female|85 |1935-11-17    |BOULOGNE-BILLANCOURT|92100      |FR  |O+            |\n",
      "|19        |9e9619793cc0e002c58830c15b9f22f36bfbe9b9f754b3773793babb93eada0a|c987ec22537e8e1e5014cfd6a58f0d1cdae3d89e7e946c6f39a92783a6af63db|male  |72 |1949-01-11    |TOULOUSE            |31000      |FR  |O+            |\n",
      "|41        |d92562a35cbf9983d5a3abe305e53b484de59e3135050cb7019e7e43eec923ee|9b09eca20ded08391c8e7322589df9164c24b2204e8cb4408b1c34bee0f5a1fd|female|92 |1929-04-07    |ORANGE              |84100      |FR  |O+            |\n",
      "|43        |4660c3e4c8287faa464926876a1a6ad2a414c2cc74f818ecb298a87f94be1fa0|f7268b0c0520e34f7a99a1641f34a82a043985e5ab4c39b4d28439207cf6a53e|female|10 |2010-07-09    |SAINT-HERBLAIN      |44800      |FR  |O+            |\n",
      "+----------+----------------------------------------------------------------+----------------------------------------------------------------+------+---+--------------+--------------------+-----------+----+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Saved: /home/jovyan/data/gold/dim_patient\n"
     ]
    }
   ],
   "source": [
    "# 2. DIM_PATIENT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIMENSION: dim_patient\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = spark.read.parquet(f\"{SILVER_BASE}/patient\")\n",
    "dim_patient = df.select(\n",
    "    F.col(\"id_patient\"),\n",
    "    F.col(\"nom_hash\"),\n",
    "    F.col(\"prenom_hash\"),\n",
    "    F.col(\"sexe\"),\n",
    "    F.col(\"age\"),\n",
    "    F.col(\"date_naissance\"),\n",
    "    F.col(\"ville\"),\n",
    "    F.col(\"code_postal\"),\n",
    "    F.col(\"pays\"),\n",
    "    F.col(\"groupe_sanguin\")\n",
    ")\n",
    "\n",
    "print(f\"{dim_patient.count():,} patients\")\n",
    "dim_patient.show(5, truncate=False)\n",
    "\n",
    "dim_patient.write.mode(\"overwrite\").parquet(f\"{GOLD_OUTPUT}/dim_patient\")\n",
    "print(f\"Saved: {GOLD_OUTPUT}/dim_patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DIM_DIAGNOSTIC\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIMENSION: dim_diagnostic\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = spark.read.parquet(f\"{SILVER_BASE}/diagnostic\")\n",
    "dim_diagnostic = df.select(\n",
    "    F.col(\"Code_diag\").alias(\"code_diag\"),\n",
    "    F.col(\"Diagnostic\").alias(\"libelle\"),\n",
    "    F.col(\"Code_diag\").substr(1, 1).alias(\"categorie\")\n",
    ").dropDuplicates([\"code_diag\"])\n",
    "\n",
    "print(f\"{dim_diagnostic.count():,} diagnostics\")\n",
    "dim_diagnostic.show(5, truncate=False)\n",
    "\n",
    "dim_diagnostic.write.mode(\"overwrite\").parquet(f\"{GOLD_OUTPUT}/dim_diagnostic\")\n",
    "print(f\"Saved: {GOLD_OUTPUT}/dim_diagnostic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIMENSION: dim_professionnel\n",
      "================================================================================\n",
      "1,048,575 professionnels\n",
      "+---------------+---------+----------+-------+---------------------------+\n",
      "|code_specialite|id_prof  |nom       |prenom |nom_specialite             |\n",
      "+---------------+---------+----------+-------+---------------------------+\n",
      "|ASS890091      |01A003753|CHAREYRE  |Laure  |Assistant de service social|\n",
      "|ASS890091      |01A004124|CECCARELLI|Chantal|Assistant de service social|\n",
      "|ASS890091      |01A004595|GREVOT    |Nicole |Assistant de service social|\n",
      "|ASS890091      |01A004611|CONSTANS  |Josiane|Assistant de service social|\n",
      "|ASS890091      |01A005105|MULLER    |Sylvie |Assistant de service social|\n",
      "+---------------+---------+----------+-------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Saved: /home/jovyan/data/gold/dim_professionnel\n"
     ]
    }
   ],
   "source": [
    "# 4. DIM_PROFESSIONNEL\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIMENSION: dim_professionnel\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_prof = spark.read.parquet(f\"{SILVER_BASE}/professionnel_de_sante\")\n",
    "df_spec = spark.read.parquet(f\"{SILVER_BASE}/specialites\")\n",
    "\n",
    "dim_professionnel = df_prof.select(\n",
    "    F.col(\"Identifiant\").alias(\"id_prof\"),\n",
    "    F.col(\"Nom\").alias(\"nom\"),\n",
    "    F.col(\"Prenom\").alias(\"prenom\"),\n",
    "    F.col(\"Code_specialite\").alias(\"code_specialite\")\n",
    ").dropDuplicates([\"id_prof\"]).join(\n",
    "    df_spec.select(\n",
    "        F.col(\"Code_specialite\"),\n",
    "        F.col(\"Specialite\").alias(\"nom_specialite\")\n",
    "    ),\n",
    "    on=\"code_specialite\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"{dim_professionnel.count():,} professionnels\")\n",
    "dim_professionnel.show(5, truncate=False)\n",
    "\n",
    "dim_professionnel.write.mode(\"overwrite\").parquet(f\"{GOLD_OUTPUT}/dim_professionnel\")\n",
    "print(f\"Saved: {GOLD_OUTPUT}/dim_professionnel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DIMENSION: dim_etablissement\n",
      "================================================================================\n",
      "200 etablissements\n",
      "+---------+-----+-------------------------------------+-------------------------+-----------+----------+-----+----------------+---------------+-------------------+--------------------+----------+\n",
      "|finess   |siret|nom                                  |ville                    |code_postal|telephone |email|code_departement|num_departement|libelle_departement|libelle_region      |abv_region|\n",
      "+---------+-----+-------------------------------------+-------------------------+-----------+----------+-----+----------------+---------------+-------------------+--------------------+----------+\n",
      "|180036014|NULL |CHNO DES QUINZE-VINGTS PARIS         |PARIS 12E  ARRONDISSEMENT|75012      |0140021520|NULL |75              |75             |Paris              |Ile-de-France       |IDF       |\n",
      "|200009181|NULL |CIAS AIME                            |AIME-LA-PLAGNE           |73211      |NULL      |NULL |73              |73             |Savoie             |Auvergne-Rh�ne-Alpes|ARA       |\n",
      "|200034650|NULL |CH INTERCOMMUNAL COMPIÈGNE-NOYON     |COMPIÈGNE                |60321      |0344236000|NULL |60              |60             |Oise               |Hauts-de-France     |HDF       |\n",
      "|200044972|NULL |CH CHATEAUBRIANT NOZAY POUANCE       |CHÂTEAUBRIANT            |44146      |0240558800|NULL |44              |44             |Loire-Atlantique   |Pays de la Loire    |PDL       |\n",
      "|200047835|NULL |CH GRPE HOSP. DE LA_ROCHELLE-RE-AUNIS|LA ROCHELLE              |17019      |0646455050|NULL |17              |17             |Charente-Maritime  |Nouvelle-Aquitaine  |NAQ       |\n",
      "+---------+-----+-------------------------------------+-------------------------+-----------+----------+-----+----------------+---------------+-------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Saved: /home/jovyan/data/gold/dim_etablissement\n"
     ]
    }
   ],
   "source": [
    "# 5. DIM_ETABLISSEMENT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIMENSION: dim_etablissement\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_etab = spark.read.parquet(f\"{SILVER_BASE}/etablissement_sante\")\n",
    "df_dept = spark.read.parquet(\"/home/jovyan/data/bronze/csv/departements\")\n",
    "\n",
    "dim_etablissement = df_etab.select(\n",
    "    F.col(\"finess_site\").alias(\"finess\"),\n",
    "    F.col(\"siret_site\").alias(\"siret\"),\n",
    "    F.col(\"raison_sociale\").alias(\"nom\"),\n",
    "    F.col(\"commune\").alias(\"ville\"),\n",
    "    F.col(\"code_postal\"),\n",
    "    F.col(\"telephone\"),\n",
    "    F.col(\"email\"),\n",
    "    F.substring(F.col(\"code_postal\"), 1, 2).alias(\"code_departement\")\n",
    ").filter(\n",
    "    F.col(\"finess\").isNotNull()\n",
    ").dropDuplicates([\"finess\"]).join(\n",
    "    df_dept.select(\n",
    "        F.col(\"num_departement\"),\n",
    "        F.col(\"libelle_departement\"),\n",
    "        F.col(\"libelle_region\"),\n",
    "        F.col(\"abv_region\")\n",
    "    ),\n",
    "    F.col(\"code_departement\") == df_dept[\"num_departement\"],\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "print(f\"{dim_etablissement.count():,} etablissements\")\n",
    "dim_etablissement.show(5, truncate=False)\n",
    "\n",
    "dim_etablissement.write.mode(\"overwrite\").parquet(f\"{GOLD_OUTPUT}/dim_etablissement\")\n",
    "print(f\"Saved: {GOLD_OUTPUT}/dim_etablissement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIT: fait_consultation\n",
      "================================================================================\n",
      "1,027,157 consultations\n",
      "+---------------+----------+-----------+---------+-----------+--------+-----------------+-----+----+----+-------------------+-------------------+-------------------+\n",
      "|id_consultation|id_patient|    id_prof|code_diag|id_mutuelle|id_temps|date_consultation|annee|mois|jour|        heure_debut|          heure_fin|              motif|\n",
      "+---------------+----------+-----------+---------+-----------+--------+-----------------+-----+----+----+-------------------+-------------------+-------------------+\n",
      "|     1059023408|      1285|10101362548|   S92700|        243|20150620|       2015-06-20| 2015|   6|  20|1970-01-01 08:00:00|1970-01-01 12:00:00|       Consultation|\n",
      "|     1059023414|      4709|10100154573|    M4140|        182|20150620|       2015-06-20| 2015|   6|  20|1970-01-01 08:00:00|1970-01-01 12:00:00|       Consultation|\n",
      "|     1059023450|     14775|10002434180|     T733|        197|20150620|       2015-06-20| 2015|   6|  20|1970-01-01 08:00:00|1970-01-01 12:00:00|       Consultation|\n",
      "|     1059023456|     16361|10003083655|   O43903|        165|20150620|       2015-06-20| 2015|   6|  20|1970-01-01 08:00:00|1970-01-01 12:00:00|Radiologie generale|\n",
      "|     1059023467|     20098|10003796314|    M8648|        203|20150620|       2015-06-20| 2015|   6|  20|1970-01-01 08:00:00|1970-01-01 12:00:00|       Consultation|\n",
      "+---------------+----------+-----------+---------+-----------+--------+-----------------+-----+----+----+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Saved: /home/jovyan/data/gold/fait_consultation (partitioned by annee, mois)\n"
     ]
    }
   ],
   "source": [
    "# 6. FAIT_CONSULTATION\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FAIT: fait_consultation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = spark.read.parquet(f\"{SILVER_BASE}/consultation\")\n",
    "\n",
    "fait_consultation = df.select(\n",
    "    F.col(\"id_consultation\"),\n",
    "    F.col(\"id_patient\"),\n",
    "    F.col(\"id_professionnel\").alias(\"id_prof\"),\n",
    "    F.col(\"id_diagnostic\").alias(\"code_diag\"),\n",
    "    F.col(\"id_mutuelle\"),\n",
    "    F.date_format(F.col(\"date_consultation\"), \"yyyyMMdd\").alias(\"id_temps\"),\n",
    "    F.col(\"date_consultation\"),\n",
    "    F.col(\"annee\"),\n",
    "    F.col(\"mois\"),\n",
    "    F.col(\"jour\"),\n",
    "    F.col(\"heure_debut\"),\n",
    "    F.col(\"heure_fin\"),\n",
    "    F.col(\"motif\")\n",
    ")\n",
    "\n",
    "print(f\"{fait_consultation.count():,} consultations\")\n",
    "fait_consultation.show(5)\n",
    "\n",
    "fait_consultation.write.mode(\"overwrite\").partitionBy(\"annee\", \"mois\").parquet(f\"{GOLD_OUTPUT}/fait_consultation\")\n",
    "print(f\"Saved: {GOLD_OUTPUT}/fait_consultation (partitioned by annee, mois)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIT: fait_deces\n",
      "================================================================================\n",
      "620,625 deces\n",
      "+--------+--------------------+--------------------+--------------------+----+--------------+----------+---------+--------+-----+----+-------------------+--------------------+--------------+---------------+\n",
      "|id_deces|            nom_hash|         prenom_hash|     acte_deces_hash|sexe|date_naissance|date_deces|age_deces|id_temps|annee|mois|code_lieu_naissance|      lieu_naissance|pays_naissance|code_lieu_deces|\n",
      "+--------+--------------------+--------------------+--------------------+----+--------------+----------+---------+--------+-----+----+-------------------+--------------------+--------------+---------------+\n",
      "|       0|58d6b0c06a55864a3...|a29c7480d5f59f49c...|19581e27de7ced00f...|   2|    1925-12-20|2019-01-05|       94|20190105| 2019|   1|              64259|             HELETTE|          NULL|          64160|\n",
      "|       1|a0409b8b554db5961...|f2e78f624016938ca...|73475cb40a568e8da...|   2|    1952-11-04|2019-04-22|       67|20190422| 2019|   4|              14437|          MONDEVILLE|          NULL|          14341|\n",
      "|       2|67bcec15b312a6644...|a79e03226a617c6ff...|99ee50221221864d5...|   2|    1921-10-27|2019-08-25|       98|20190825| 2019|   8|              33063|            BORDEAUX|          NULL|          33063|\n",
      "|       3|3e75f1736dc325896...|a27096b553e4df230...|2858dcd1057d3eae7...|   1|    1920-02-22|2019-04-14|       99|20190414| 2019|   4|              75115|PARIS 15E  ARROND...|          NULL|          72003|\n",
      "|       4|1c1bd03ce5ddf82bf...|d0e4170569cc37dba...|826e27285307a9237...|   1|    1945-02-17|2019-02-21|       74|20190221| 2019|   2|              29168|             PLOGOFF|          NULL|          29019|\n",
      "+--------+--------------------+--------------------+--------------------+----+--------------+----------+---------+--------+-----+----+-------------------+--------------------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Saved: /home/jovyan/data/gold/fait_deces (partitioned by annee, mois)\n"
     ]
    }
   ],
   "source": [
    "# 7. FAIT_DECES\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FAIT: fait_deces\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = spark.read.parquet(f\"{SILVER_BASE}/deces_2019\")\n",
    "\n",
    "fait_deces = df.select(\n",
    "    F.monotonically_increasing_id().alias(\"id_deces\"),\n",
    "    F.col(\"nom_hash\"),\n",
    "    F.col(\"prenom_hash\"),\n",
    "    F.col(\"acte_deces_hash\"),\n",
    "    F.col(\"sexe\"),\n",
    "    F.col(\"date_naissance\"),\n",
    "    F.col(\"date_deces\"),\n",
    "    F.col(\"age_deces\"),\n",
    "    F.date_format(F.col(\"date_deces\"), \"yyyyMMdd\").alias(\"id_temps\"),\n",
    "    F.col(\"annee_deces\").alias(\"annee\"),\n",
    "    F.col(\"mois_deces\").alias(\"mois\"),\n",
    "    F.col(\"code_lieu_naissance\"),\n",
    "    F.col(\"lieu_naissance\"),\n",
    "    F.col(\"pays_naissance\"),\n",
    "    F.col(\"code_lieu_deces\")\n",
    ")\n",
    "\n",
    "print(f\"{fait_deces.count():,} deces\")\n",
    "fait_deces.show(5)\n",
    "\n",
    "fait_deces.write.mode(\"overwrite\").partitionBy(\"annee\", \"mois\").parquet(f\"{GOLD_OUTPUT}/fait_deces\")\n",
    "print(f\"Saved: {GOLD_OUTPUT}/fait_deces (partitioned by annee, mois)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIT: fait_hospitalisation\n",
      "================================================================================\n",
      "82,216 hospitalisations\n",
      "+------------------+----------+---------+-----------+-----------+---------------+---------------+------------------+-----+----+\n",
      "|id_hospitalisation|id_patient|code_diag|date_entree|date_sortie|id_temps_entree|id_temps_sortie|duree_sejour_jours|annee|mois|\n",
      "+------------------+----------+---------+-----------+-----------+---------------+---------------+------------------+-----+----+\n",
      "|                 0|         1|     Q428| 2018-12-01| 2018-12-02|       20181201|       20181202|                 1| 2018|  12|\n",
      "|                 1|         2|     G961| 2019-03-12| 2019-03-13|       20190312|       20190313|                 1| 2019|   3|\n",
      "|                 2|         3|     J350| 2015-12-27| 2015-12-28|       20151227|       20151228|                 1| 2015|  12|\n",
      "|                 3|         4|     P569| 2017-09-20| 2017-09-21|       20170920|       20170921|                 1| 2017|   9|\n",
      "|                 4|         5|    M0217| 2021-04-06| 2021-04-07|       20210406|       20210407|                 1| 2021|   4|\n",
      "+------------------+----------+---------+-----------+-----------+---------------+---------------+------------------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Saved: /home/jovyan/data/gold/fait_hospitalisation (partitioned by annee, mois)\n"
     ]
    }
   ],
   "source": [
    "# 8. FAIT_HOSPITALISATION (depuis AAAA + date)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FAIT: fait_hospitalisation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_aaaa = spark.read.parquet(f\"{SILVER_BASE}/../bronze/postgres/AAAA\").drop(\"ingestion_timestamp\", \"ingestion_date\")\n",
    "df_date = spark.read.parquet(f\"{SILVER_BASE}/../bronze/postgres/date\").drop(\"ingestion_timestamp\", \"ingestion_date\")\n",
    "\n",
    "df_aaaa_idx = df_aaaa.withColumn(\"row_id\", F.monotonically_increasing_id())\n",
    "df_date_idx = df_date.withColumn(\"row_id\", F.monotonically_increasing_id())\n",
    "\n",
    "df_hospit = df_aaaa_idx.join(df_date_idx, \"row_id\", \"inner\")\n",
    "\n",
    "fait_hospitalisation = df_hospit.select(\n",
    "    F.monotonically_increasing_id().alias(\"id_hospitalisation\"),\n",
    "    F.col(\"Num\").alias(\"id_patient\"),\n",
    "    F.col(\"Code_diag\").alias(\"code_diag\"),\n",
    "    F.to_date(F.col(\"date1\"), \"dd/MM/yyyy\").alias(\"date_entree\"),\n",
    "    F.to_date(F.col(\"date2\"), \"dd/MM/yyyy\").alias(\"date_sortie\"),\n",
    "    F.date_format(F.to_date(F.col(\"date1\"), \"dd/MM/yyyy\"), \"yyyyMMdd\").alias(\"id_temps_entree\"),\n",
    "    F.date_format(F.to_date(F.col(\"date2\"), \"dd/MM/yyyy\"), \"yyyyMMdd\").alias(\"id_temps_sortie\"),\n",
    "    F.datediff(F.to_date(F.col(\"date2\"), \"dd/MM/yyyy\"), F.to_date(F.col(\"date1\"), \"dd/MM/yyyy\")).alias(\"duree_sejour_jours\"),\n",
    "    F.year(F.to_date(F.col(\"date1\"), \"dd/MM/yyyy\")).alias(\"annee\"),\n",
    "    F.month(F.to_date(F.col(\"date1\"), \"dd/MM/yyyy\")).alias(\"mois\")\n",
    ").filter(\n",
    "    (F.col(\"date_entree\").isNotNull()) &\n",
    "    (F.col(\"date_sortie\").isNotNull()) &\n",
    "    (F.col(\"duree_sejour_jours\") >= 0)\n",
    ")\n",
    "\n",
    "print(f\"{fait_hospitalisation.count():,} hospitalisations\")\n",
    "fait_hospitalisation.show(5)\n",
    "\n",
    "fait_hospitalisation.write.mode(\"overwrite\").partitionBy(\"annee\", \"mois\").parquet(f\"{GOLD_OUTPUT}/fait_hospitalisation\")\n",
    "print(f\"Saved: {GOLD_OUTPUT}/fait_hospitalisation (partitioned by annee, mois)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIT: fait_satisfaction\n",
      "================================================================================\n",
      "8 evaluations\n",
      "+---------------+---------+--------+-----+------------+-------------+-------------------+-----------------+-------------+-----------+------------+-------------------+-------------+------------------+----------+------------+\n",
      "|id_satisfaction|   finess|id_temps|annee|score_global|score_accueil|score_pec_infirmier|score_pec_medical|score_chambre|score_repas|score_sortie|taux_recommandation|nb_repondants|nb_recommandations|classement|   evolution|\n",
      "+---------------+---------+--------+-----+------------+-------------+-------------------+-----------------+-------------+-----------+------------+-------------------+-------------+------------------+----------+------------+\n",
      "|              0|070780358|20190101| 2019|        71.0|        71.15|              79.19|            76.45|         68.8|      57.64|       61.17|               41.0|          307|               305|         C|1-Diminution|\n",
      "|              1|180000358|20190101| 2019|        76.0|        78.05|              82.42|            79.54|        75.46|      65.26|       67.11|               NULL|           78|                78|         B|    2-Stable|\n",
      "|              2|380785956|20190101| 2019|        77.0|        77.35|              83.23|            83.35|        75.72|      64.76|       67.85|               63.0|         1045|              1041|         B|1-Diminution|\n",
      "|              3|640018206|20190101| 2019|        76.0|        75.57|               82.2|            82.21|        81.18|      60.88|       63.63|               NULL|          326|               325|         B|1-Diminution|\n",
      "|              4|670780055|20190101| 2019|        73.0|        74.35|              80.96|            79.09|        75.81|      53.11|       61.03|               NULL|          987|               983|         C|    2-Stable|\n",
      "+---------------+---------+--------+-----+------------+-------------+-------------------+-----------------+-------------+-----------+------------+-------------------+-------------+------------------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Saved: /home/jovyan/data/gold/fait_satisfaction (partitioned by annee)\n"
     ]
    }
   ],
   "source": [
    "# 9. FAIT_SATISFACTION\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FAIT: fait_satisfaction\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = spark.read.parquet(f\"{SILVER_BASE}/satisfaction_2019\")\n",
    "\n",
    "fait_satisfaction = df.select(\n",
    "    F.monotonically_increasing_id().alias(\"id_satisfaction\"),\n",
    "    F.col(\"finess\"),\n",
    "    F.lit(\"20190101\").alias(\"id_temps\"),\n",
    "    F.col(\"annee\"),\n",
    "    F.col(\"score_global\"),\n",
    "    F.col(\"score_accueil\"),\n",
    "    F.col(\"score_pec_infirmier\"),\n",
    "    F.col(\"score_pec_medical\"),\n",
    "    F.col(\"score_chambre\"),\n",
    "    F.col(\"score_repas\"),\n",
    "    F.col(\"score_sortie\"),\n",
    "    F.col(\"taux_recommandation\"),\n",
    "    F.col(\"nb_reponses_global\").alias(\"nb_repondants\"),\n",
    "    F.col(\"nb_recommandations\"),\n",
    "    F.col(\"classement\"),\n",
    "    F.col(\"evolution\")\n",
    ")\n",
    "\n",
    "print(f\"{fait_satisfaction.count():,} evaluations\")\n",
    "fait_satisfaction.show(5)\n",
    "\n",
    "fait_satisfaction.write.mode(\"overwrite\").partitionBy(\"annee\").parquet(f\"{GOLD_OUTPUT}/fait_satisfaction\")\n",
    "print(f\"Saved: {GOLD_OUTPUT}/fait_satisfaction (partitioned by annee)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VERIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GOLD LAYER - INVENTAIRE\n",
      "================================================================================\n",
      "DIM  | dim_diagnostic                 |     15,490 rows |  3 cols\n",
      "DIM  | dim_etablissement              |        200 rows | 12 cols\n",
      "DIM  | dim_patient                    |    100,000 rows | 10 cols\n",
      "DIM  | dim_professionnel              |  1,048,575 rows |  5 cols\n",
      "DIM  | dim_temps                      |      4,748 rows |  9 cols\n",
      "FAIT | fait_consultation              |  1,027,157 rows | 13 cols\n",
      "FAIT | fait_deces                     |    620,625 rows | 15 cols\n",
      "FAIT | fait_hospitalisation           |     82,216 rows | 10 cols\n",
      "FAIT | fait_satisfaction              |          8 rows | 16 cols\n",
      "================================================================================\n",
      "GOLD LAYER COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Inventaire Gold\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GOLD LAYER - INVENTAIRE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for table in sorted(os.listdir(GOLD_OUTPUT)):\n",
    "    path = f\"{GOLD_OUTPUT}/{table}\"\n",
    "    try:\n",
    "        df = spark.read.parquet(path)\n",
    "        count = df.count()\n",
    "        cols = len(df.columns)\n",
    "        table_type = \"DIM\" if table.startswith(\"dim_\") else \"FAIT\"\n",
    "        print(f\"{table_type:4s} | {table:30s} | {count:>10,} rows | {cols:>2} cols\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR | {table:30s} | {str(e)[:50]}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GOLD LAYER COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark stopped\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"Spark stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
