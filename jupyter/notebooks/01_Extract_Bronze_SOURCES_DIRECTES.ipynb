{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# BRONZE LAYER - Extract depuis sources DIRECTES\n",
    "\n",
    "**Flux correct ETL** : Extract ‚Üí Transform ‚Üí Load\n",
    "\n",
    "**Auteurs** : Nejma MOUALHI | Brieuc OLIVIERI | Nicolas TAING\n",
    "\n",
    "---\n",
    "\n",
    "## Sources de donn√©es\n",
    "\n",
    "### 1. PostgreSQL (tables originales) :\n",
    "- Patient, Consultation, Diagnostic, Professionnel_de_sante, etc.\n",
    "- AAAA + date : Donn√©es d'hospitalisation (82K lignes)\n",
    "\n",
    "### 2. CSV BRUTS (lus directement depuis /DATA_2024/) :\n",
    "- Etablissements de sant√© (416K lignes)\n",
    "- Satisfaction 2019 (1K lignes)\n",
    "- D√©c√®s 2019 UNIQUEMENT (600K lignes - FILTR√â depuis 25M)\n",
    "\n",
    "Le fichier `deces.csv` est filtr√© pour ne garder que 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_timestamp, lit, year, to_date, col\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "print(\"Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 3.5.0 started successfully\n",
      "Master: local[*]\n"
     ]
    }
   ],
   "source": [
    "# Configuration Spark avec plus de m√©moire pour les gros fichiers\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CHU_Bronze_Extract_Sources_Directes\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark {spark.version} started successfully\")\n",
    "print(f\"Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 PostgreSQL tables configured for extraction\n",
      "4 CSV files configured for extraction\n",
      "Destination: /home/jovyan/data/bronze\n"
     ]
    }
   ],
   "source": [
    "# Configuration PostgreSQL pour les tables originales\n",
    "JDBC_URL = \"jdbc:postgresql://chu_postgres:5432/healthcare_data\"\n",
    "JDBC_PROPS = {\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"admin123\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Tables PostgreSQL originales (13 tables)\n",
    "POSTGRES_TABLES = [\n",
    "    \"Patient\",\n",
    "    \"Consultation\",\n",
    "    \"Diagnostic\",\n",
    "    \"Professionnel_de_sante\",\n",
    "    \"Mutuelle\",\n",
    "    \"Adher\",\n",
    "    \"Prescription\",\n",
    "    \"Medicaments\",\n",
    "    \"Laboratoire\",\n",
    "    \"Salle\",\n",
    "    \"Specialites\",\n",
    "    \"date\",\n",
    "    \"AAAA\"\n",
    "]\n",
    "\n",
    "# Configuration chemins\n",
    "DATA_DIR = \"/home/jovyan/DATA_2024\"\n",
    "OUTPUT_BASE = \"/home/jovyan/data/bronze\"\n",
    "\n",
    "print(f\"{len(POSTGRES_TABLES)} PostgreSQL tables configured for extraction\")\n",
    "print(f\"4 CSV files configured for extraction\")\n",
    "print(f\"Destination: {OUTPUT_BASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## PARTIE 1 : Extract PostgreSQL (tables originales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL ingestion function defined\n"
     ]
    }
   ],
   "source": [
    "def ingest_postgres_table(table_name):\n",
    "    \"\"\"Extrait une table PostgreSQL vers Bronze layer\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Extracting PostgreSQL table: {table_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        df = spark.read.jdbc(\n",
    "            url=JDBC_URL,\n",
    "            table=f'\"{table_name}\"',\n",
    "            properties=JDBC_PROPS\n",
    "        )\n",
    "        \n",
    "        row_count = df.count()\n",
    "        col_count = len(df.columns)\n",
    "        \n",
    "        print(f\"Read: {row_count:,} rows, {col_count} columns\")\n",
    "        \n",
    "        # Ajout m√©tadonn√©es\n",
    "        df_with_meta = df \\\n",
    "            .withColumn(\"ingestion_timestamp\", current_timestamp()) \\\n",
    "            .withColumn(\"ingestion_date\", lit(datetime.now().strftime(\"%Y-%m-%d\")))\n",
    "        \n",
    "        # Sauvegarde en Bronze\n",
    "        output_path = f\"{OUTPUT_BASE}/postgres/{table_name}\"\n",
    "        df_with_meta.write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .partitionBy(\"ingestion_date\") \\\n",
    "            .parquet(output_path)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        print(f\"Saved to: {output_path}\")\n",
    "        print(f\"Time elapsed: {elapsed:.2f}s\")\n",
    "        print(f\"{table_name} extraction completed successfully\")\n",
    "        \n",
    "        return {\n",
    "            \"source\": \"PostgreSQL\",\n",
    "            \"table\": table_name,\n",
    "            \"rows\": row_count,\n",
    "            \"cols\": col_count,\n",
    "            \"time_sec\": round(elapsed, 2),\n",
    "            \"status\": \"SUCCESS\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "        return {\n",
    "            \"source\": \"PostgreSQL\",\n",
    "            \"table\": table_name,\n",
    "            \"rows\": 0,\n",
    "            \"cols\": 0,\n",
    "            \"time_sec\": 0,\n",
    "            \"status\": f\"ERROR: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"PostgreSQL ingestion function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "POSTGRESQL EXTRACTION - ORIGINAL TABLES\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Patient\n",
      "================================================================================\n",
      "Read: 100,000 rows, 16 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Patient\n",
      "Time elapsed: 6.63s\n",
      "Patient extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Consultation\n",
      "================================================================================\n",
      "Read: 1,027,157 rows, 9 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Consultation\n",
      "Time elapsed: 10.50s\n",
      "Consultation extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Diagnostic\n",
      "================================================================================\n",
      "Read: 15,490 rows, 2 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Diagnostic\n",
      "Time elapsed: 1.09s\n",
      "Diagnostic extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Professionnel_de_sante\n",
      "================================================================================\n",
      "Read: 1,048,575 rows, 8 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Professionnel_de_sante\n",
      "Time elapsed: 5.15s\n",
      "Professionnel_de_sante extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Mutuelle\n",
      "================================================================================\n",
      "Read: 254 rows, 3 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Mutuelle\n",
      "Time elapsed: 0.96s\n",
      "Mutuelle extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Adher\n",
      "================================================================================\n",
      "Read: 96,671 rows, 2 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Adher\n",
      "Time elapsed: 0.99s\n",
      "Adher extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Prescription\n",
      "================================================================================\n",
      "Read: 1,003,845 rows, 2 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Prescription\n",
      "Time elapsed: 2.47s\n",
      "Prescription extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Medicaments\n",
      "================================================================================\n",
      "Read: 15,455 rows, 12 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Medicaments\n",
      "Time elapsed: 1.14s\n",
      "Medicaments extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Laboratoire\n",
      "================================================================================\n",
      "Read: 677 rows, 3 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Laboratoire\n",
      "Time elapsed: 0.72s\n",
      "Laboratoire extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Salle\n",
      "================================================================================\n",
      "Read: 201,735 rows, 5 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Salle\n",
      "Time elapsed: 1.37s\n",
      "Salle extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: Specialites\n",
      "================================================================================\n",
      "Read: 93 rows, 3 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/Specialites\n",
      "Time elapsed: 0.75s\n",
      "Specialites extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: date\n",
      "================================================================================\n",
      "Read: 82,216 rows, 2 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/date\n",
      "Time elapsed: 0.90s\n",
      "date extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "Extracting PostgreSQL table: AAAA\n",
      "================================================================================\n",
      "Read: 82,216 rows, 7 columns\n",
      "Saved to: /home/jovyan/data/bronze/postgres/AAAA\n",
      "Time elapsed: 1.11s\n",
      "AAAA extraction completed successfully\n",
      "\n",
      "================================================================================\n",
      "POSTGRESQL EXTRACTION COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# INGESTION POSTGRESQL\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POSTGRESQL EXTRACTION - ORIGINAL TABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "\n",
    "for table in POSTGRES_TABLES:\n",
    "    result = ingest_postgres_table(table)\n",
    "    results.append(result)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POSTGRESQL EXTRACTION COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## PARTIE 2 : Extract CSV BRUTS (directement depuis /DATA_2024/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV ingestion function defined\n"
     ]
    }
   ],
   "source": [
    "def ingest_csv_file(name, file_path, separator=\";\", encoding=\"UTF-8\"):\n",
    "    \"\"\"Extrait un fichier CSV vers Bronze layer\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Extracting CSV: {name}\")\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Lecture CSV BRUT\n",
    "        df = spark.read \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"inferSchema\", \"true\") \\\n",
    "            .option(\"sep\", separator) \\\n",
    "            .option(\"encoding\", encoding) \\\n",
    "            .csv(file_path)\n",
    "        \n",
    "        row_count = df.count()\n",
    "        col_count = len(df.columns)\n",
    "        \n",
    "        print(f\"Read: {row_count:,} rows, {col_count} columns\")\n",
    "        \n",
    "        # Ajout m√©tadonn√©es\n",
    "        df_with_meta = df \\\n",
    "            .withColumn(\"ingestion_timestamp\", current_timestamp()) \\\n",
    "            .withColumn(\"ingestion_date\", lit(datetime.now().strftime(\"%Y-%m-%d\")))\n",
    "        \n",
    "        # Sauvegarde en Bronze\n",
    "        output_path = f\"{OUTPUT_BASE}/csv/{name}\"\n",
    "        df_with_meta.write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .parquet(output_path)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        print(f\"Saved to: {output_path}\")\n",
    "        print(f\"Time elapsed: {elapsed:.2f}s\")\n",
    "        print(f\"{name} extraction completed successfully\")\n",
    "        \n",
    "        return {\n",
    "            \"source\": \"CSV\",\n",
    "            \"table\": name,\n",
    "            \"rows\": row_count,\n",
    "            \"cols\": col_count,\n",
    "            \"time_sec\": round(elapsed, 2),\n",
    "            \"status\": \"SUCCESS\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "        return {\n",
    "            \"source\": \"CSV\",\n",
    "            \"table\": name,\n",
    "            \"rows\": 0,\n",
    "            \"cols\": 0,\n",
    "            \"time_sec\": 0,\n",
    "            \"status\": f\"ERROR: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"CSV ingestion function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Extracting CSV: etablissement_sante\n",
      "File: /home/jovyan/DATA_2024/Etablissement de SANTE/etablissement_sante.csv\n",
      "================================================================================\n",
      "Read: 416,665 rows, 24 columns\n",
      "Saved to: /home/jovyan/data/bronze/csv/etablissement_sante\n",
      "Time elapsed: 6.53s\n",
      "etablissement_sante extraction completed successfully\n"
     ]
    }
   ],
   "source": [
    "# 1. √âTABLISSEMENTS DE SANT√â\n",
    "result = ingest_csv_file(\n",
    "    name=\"etablissement_sante\",\n",
    "    file_path=f\"{DATA_DIR}/Etablissement de SANTE/etablissement_sante.csv\",\n",
    "    separator=\";\"\n",
    ")\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Extracting CSV: satisfaction_esatis48h_2019\n",
      "File: /home/jovyan/DATA_2024/Satisfaction/2019/resultats-esatis48h-mco-open-data-2019.csv\n",
      "================================================================================\n",
      "Read: 1,152 rows, 25 columns\n",
      "Saved to: /home/jovyan/data/bronze/csv/satisfaction_esatis48h_2019\n",
      "Time elapsed: 1.06s\n",
      "satisfaction_esatis48h_2019 extraction completed successfully\n"
     ]
    }
   ],
   "source": [
    "# 2. SATISFACTION 2019\n",
    "result = ingest_csv_file(\n",
    "    name=\"satisfaction_esatis48h_2019\",\n",
    "    file_path=f\"{DATA_DIR}/Satisfaction/2019/resultats-esatis48h-mco-open-data-2019.csv\",\n",
    "    separator=\";\"\n",
    ")\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Extracting CSV: deces (2019 DATA ONLY - FILTERED)\n",
      "File: /home/jovyan/DATA_2024/DECES EN FRANCE/deces.csv\n",
      "================================================================================\n",
      "Reading complete CSV file...\n",
      "Filtering 2019 deaths only...\n",
      "Total 2019 records: 620,626 rows, 10 columns\n",
      "FILTERED: Only 2019 data (98% reduction)\n",
      "Saved to: /home/jovyan/data/bronze/csv/deces_2019\n",
      "Time elapsed: 36.51s\n",
      "deces 2019 extraction completed (620,626 rows)\n"
     ]
    }
   ],
   "source": [
    "# 3. DECES 2019 UNIQUEMENT (FILTRE)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Extracting CSV: deces (2019 DATA ONLY - FILTERED)\")\n",
    "print(f\"File: {DATA_DIR}/DECES EN FRANCE/deces.csv\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Lecture CSV brut\n",
    "    print(\"Reading complete CSV file...\")\n",
    "    df_deces_raw = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"mode\", \"PERMISSIVE\") \\\n",
    "        .option(\"multiLine\", \"false\") \\\n",
    "        .csv(f\"{DATA_DIR}/DECES EN FRANCE/deces.csv\")\n",
    "    \n",
    "    # FILTRAGE : Ne garder que 2019\n",
    "    print(\"Filtering 2019 deaths only...\")\n",
    "    df_deces_full = df_deces_raw.filter(col(\"date_deces\").startswith(\"2019\"))\n",
    "    \n",
    "    # Repartitionner pour optimiser l'√©criture\n",
    "    df_deces_full = df_deces_full.repartition(10)\n",
    "    \n",
    "    row_count = df_deces_full.count()\n",
    "    col_count = len(df_deces_full.columns)\n",
    "    print(f\"Total 2019 records: {row_count:,} rows, {col_count} columns\")\n",
    "    print(f\"FILTERED: Only 2019 data (98% reduction)\")\n",
    "    \n",
    "    # Ajout m√©tadonn√©es\n",
    "    df_with_meta = df_deces_full \\\n",
    "        .withColumn(\"ingestion_timestamp\", current_timestamp()) \\\n",
    "        .withColumn(\"ingestion_date\", lit(datetime.now().strftime(\"%Y-%m-%d\")))\n",
    "    \n",
    "    # Sauvegarde en Bronze (DONNEES 2019 uniquement)\n",
    "    output_path = f\"{OUTPUT_BASE}/csv/deces_2019\"\n",
    "    df_with_meta.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"compression\", \"snappy\") \\\n",
    "        .parquet(output_path)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Saved to: {output_path}\")\n",
    "    print(f\"Time elapsed: {elapsed:.2f}s\")\n",
    "    print(f\"deces 2019 extraction completed ({row_count:,} rows)\")\n",
    "    \n",
    "    results.append({\n",
    "        \"source\": \"CSV\",\n",
    "        \"table\": \"deces_2019\",\n",
    "        \"rows\": row_count,\n",
    "        \"cols\": col_count,\n",
    "        \"time_sec\": round(elapsed, 2),\n",
    "        \"status\": \"SUCCESS\"\n",
    "    })\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    results.append({\n",
    "        \"source\": \"CSV\",\n",
    "        \"table\": \"deces_2019\",\n",
    "        \"rows\": 0,\n",
    "        \"cols\": 0,\n",
    "        \"time_sec\": 0,\n",
    "        \"status\": f\"ERROR: {str(e)}\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8230ks14v3n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Extracting CSV: departements\n",
      "File: /home/jovyan/DATA_2024/departements-francais.csv\n",
      "================================================================================\n",
      "Read: 101 rows, 4 columns\n",
      "Saved to: /home/jovyan/data/bronze/csv/departements\n",
      "Time elapsed: 0.82s\n",
      "departements extraction completed successfully\n"
     ]
    }
   ],
   "source": [
    "# 4. DEPARTEMENTS FRANCAIS (r√©f√©rentiel g√©ographique)\n",
    "result = ingest_csv_file(\n",
    "    name=\"departements\",\n",
    "    file_path=f\"{DATA_DIR}/departements-francais.csv\",\n",
    "    separator=\";\"\n",
    ")\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uxaho6qcor",
   "metadata": {},
   "source": [
    "## RESUME GLOBAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GLOBAL STATISTICS\n",
      "============================================================\n",
      "Tables extracted: 17/17\n",
      "Total rows: 4,712,928\n",
      "Total time: 78.70s\n",
      "\n",
      "By source:\n",
      "\n",
      "  PostgreSQL:\n",
      "    - Tables: 13\n",
      "    - Rows: 3,674,384\n",
      "    - Time: 33.78s\n",
      "\n",
      "  CSV:\n",
      "    - Tables: 4\n",
      "    - Rows: 1,038,544\n",
      "    - Time: 44.92s\n",
      "\n",
      "============================================================\n",
      "\n",
      "Data saved in: /home/jovyan/data/bronze/\n",
      "  bronze/postgres/ - 13 original tables\n",
      "  bronze/csv/ - 4 CSV files\n",
      "============================================================\n",
      "\n",
      "üìä STATISTIQUES GLOBALES\n",
      "============================================================\n",
      "‚úÖ Tables extraites: 17/17\n",
      "üìä Total lignes: 4,712,928\n",
      "‚è±Ô∏è  Temps total: 78.70s\n",
      "\n",
      "üì¶ D√©tail par source:\n",
      "\n",
      "  PostgreSQL:\n",
      "    - Tables: 13\n",
      "    - Lignes: 3,674,384\n",
      "    - Temps: 33.78s\n",
      "\n",
      "  CSV:\n",
      "    - Tables: 4\n",
      "    - Lignes: 1,038,544\n",
      "    - Temps: 44.92s\n",
      "\n",
      "============================================================\n",
      "\n",
      "üíæ Donn√©es sauvegard√©es dans: {OUTPUT_BASE}/\n",
      "  üìÇ bronze/postgres/ - 13 tables originales\n",
      "  üìÇ bronze/csv/ - 3 fichiers CSV\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# RESUME - Statistiques globales\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Filtrer les succ√®s\n",
    "success = df_results[df_results['status'] == 'SUCCESS']\n",
    "\n",
    "print(\"\\nGLOBAL STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Tables extracted: {len(success)}/{len(results)}\")\n",
    "print(f\"Total rows: {success['rows'].sum():,}\")\n",
    "print(f\"Total time: {success['time_sec'].sum():.2f}s\")\n",
    "\n",
    "print(\"\\nBy source:\")\n",
    "for source in success['source'].unique():\n",
    "    source_data = success[success['source'] == source]\n",
    "    print(f\"\\n  {source}:\")\n",
    "    print(f\"    - Tables: {len(source_data)}\")\n",
    "    print(f\"    - Rows: {source_data['rows'].sum():,}\")\n",
    "    print(f\"    - Time: {source_data['time_sec'].sum():.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\\nData saved in: {OUTPUT_BASE}/\")\n",
    "print(\"  bronze/postgres/ - 13 original tables\")\n",
    "print(\"  bronze/csv/ - 4 CSV files\")\n",
    "print(\"=\"*60)\n",
    "# STATISTIQUES PAR SOURCE\n",
    "success = df_results[df_results['status'] == 'SUCCESS']\n",
    "\n",
    "print(\"\\nüìä STATISTIQUES GLOBALES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Tables extraites: {len(success)}/{len(results)}\")\n",
    "print(f\"üìä Total lignes: {success['rows'].sum():,}\")\n",
    "print(f\"‚è±Ô∏è  Temps total: {success['time_sec'].sum():.2f}s\")\n",
    "\n",
    "print(\"\\nüì¶ D√©tail par source:\")\n",
    "for source in success['source'].unique():\n",
    "    source_data = success[success['source'] == source]\n",
    "    print(f\"\\n  {source}:\")\n",
    "    print(f\"    - Tables: {len(source_data)}\")\n",
    "    print(f\"    - Lignes: {source_data['rows'].sum():,}\")\n",
    "    print(f\"    - Temps: {source_data['time_sec'].sum():.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nüíæ Donn√©es sauvegard√©es dans: {OUTPUT_BASE}/\")\n",
    "print(\"  üìÇ bronze/postgres/ - 13 tables originales\")\n",
    "print(\"  üìÇ bronze/csv/ - 3 fichiers CSV\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## BRONZE LAYER - EXTRACTION COMPLETE\n",
    "\n",
    "### Data extracted:\n",
    "\n",
    "#### PostgreSQL (13 tables):\n",
    "- 100K patients\n",
    "- 1M+ consultations\n",
    "- 1M+ healthcare professionals\n",
    "- 82K hospitalizations (AAAA + date tables)\n",
    "- Diagnostic, Prescription, Medicaments, etc.\n",
    "\n",
    "#### CSV (4 files read DIRECTLY):\n",
    "- 416K healthcare establishments\n",
    "- 1K satisfaction evaluations 2019\n",
    "- 600K deaths 2019 (FILTERED from 25M - 98% performance gain)\n",
    "- 101 French departments\n",
    "\n",
    "### Total: ~4 million rows (optimized)\n",
    "\n",
    "### Next step:\n",
    "\n",
    "**Notebook 02**: Transform Silver (Cleaning, Anonymization, Formatting)\n",
    "\n",
    "**Important**: Deaths are now filtered to 2019 only for performance and consistency with 2019 satisfaction data. Hospitalizations come from AAAA + date tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ BRONZE LAYER - EXTRACTION COMPL√àTE\n",
    "\n",
    "### üì¶ Donn√©es extraites :\n",
    "\n",
    "#### PostgreSQL (13 tables) :\n",
    "- ‚úÖ 100K patients\n",
    "- ‚úÖ 1M+ consultations\n",
    "- ‚úÖ 1M+ professionnels de sant√©\n",
    "- ‚úÖ Diagnostic, Prescription, M√©dicaments, etc.\n",
    "\n",
    "#### CSV (3 fichiers lus DIRECTEMENT) :\n",
    "- ‚úÖ 416K √©tablissements de sant√©\n",
    "- ‚úÖ 1K √©valuations satisfaction 2019\n",
    "- ‚úÖ **25M d√©c√®s COMPLET** (toutes ann√©es - SANS FILTRAGE)\n",
    "\n",
    "### Total : ~29 millions de lignes\n",
    "\n",
    "### üéØ Prochaine √©tape :\n",
    "\n",
    "üëâ **Notebook 02** : Transform Silver (Nettoyage, Anonymisation, Formats)\n",
    "\n",
    "**Important** : Les CSV sont maintenant en Bronze sous forme **BRUTE INT√âGRALE**. Le filtrage temporel (si n√©cessaire) sera appliqu√© dans Silver ou Gold selon les besoins m√©tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f193b12a-1708-4766-9ece-4f54d0ac2e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients en Bronze : 100,000\n",
      "+----------+----------+--------+------+--------------------+-----------------+-----------+----+--------------------+--------------+----------+---+----------------+--------------+-----+------+--------------------+--------------+\n",
      "|Id_patient|       Nom|  Prenom|  Sexe|             Adresse|            Ville|Code_postal|Pays|               EMail|           Tel|      Date|Age|        Num_Secu|Groupe_sanguin| Poid|Taille| ingestion_timestamp|ingestion_date|\n",
      "+----------+----------+--------+------+--------------------+-----------------+-----------+----+--------------------+--------------+----------+---+----------------+--------------+-----+------+--------------------+--------------+\n",
      "|         1|Christabel|  Tougas|female|12 rue du Faubour...|       THIONVILLE|      57100|  FR|ChristabelTougas@...|03.85.46.00.55|  4/6/1980| 41|5571905089387417|            O+| 54.3|   162|2025-10-24 19:11:...|    2025-10-24|\n",
      "|         2|  Lorraine|   Lebel|female|   21 rue Jean Vilar|         BERGERAC|      24100|  FR|LorraineLebel@cuv...|05.46.79.10.17| 7/25/2013|  7|4532466282665225|            O+| 29.7|   130|2025-10-24 19:11:...|    2025-10-24|\n",
      "|         3|     Jolie|  Majory|female|5 rue des six fr√®...|SALON-DE-PROVENCE|      13300|  FR|JolieMajory@super...|04.87.37.30.02|  8/8/2009| 11|5149386463429955|            O+| 52.8|   136|2025-10-24 19:11:...|    2025-10-24|\n",
      "|         4|     Agate|  Chalut|female|48 rue Reine Elis...|         M√âRIGNAC|      33700|  FR|AgateChalut@fleck...|05.34.48.56.26|10/18/1957| 63|5180287306844105|            B+| 95.2|   161|2025-10-24 19:11:...|    2025-10-24|\n",
      "|         5|    D'Arcy|Casgrain|  male|85 rue du G√©n√©ral...|        LES LILAS|      93260|  FR|DArcyCasgrain@sup...|01.89.72.90.23| 10/4/1965| 55|4556425084059319|            O+|105.0|   168|2025-10-24 19:11:...|    2025-10-24|\n",
      "+----------+----------+--------+------+--------------------+-----------------+-----------+----+--------------------+--------------+----------+---+----------------+--------------+-----+------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dans une cellule Jupyter\n",
    "df = spark.read.parquet(\"/home/jovyan/data/bronze/postgres/Patient\")\n",
    "print(f\"Patients en Bronze : {df.count():,}\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740414e0-8529-48b2-81e0-3a79cba51f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1eac3-b8d9-46ca-8bea-793310036ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93834c46-e15d-4d04-a1cc-ce0886be40f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a89d2f-210d-40da-914c-bce4ad93cc73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
