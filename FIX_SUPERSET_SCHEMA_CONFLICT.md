# üîß FIX : Conflit de sch√©ma Hive Metastore

## ‚ùå Probl√®me rencontr√©

### Erreur dans Notebook 05

```
AnalysisException: Column in converted table has different data type with source
Hive table's. Set spark.sql.hive.convertMetastoreParquet to false, or recreate
table `spark_catalog`.`default`.`dim_temps` to workaround.
```

### Cause

**Conflit entre le metastore Hive et les fichiers Parquet** :
- Hive Metastore a enregistr√© un sch√©ma lors d'une cr√©ation pr√©c√©dente
- Les fichiers Parquet Gold ont un sch√©ma l√©g√®rement diff√©rent (ex: `DATE` vs `STRING`)
- Spark essaie de convertir automatiquement Parquet ‚Üí Hive et d√©tecte une incompatibilit√©

---

## ‚úÖ SOLUTION 1 : Configuration Spark (RECOMMAND√â)

### Modification appliqu√©e au Notebook 05

**Cellule 2 (Configuration Spark)** - Ajout de la config :

```python
spark = SparkSession.builder \
    .appName("CHU_Superset_Setup") \
    .config("spark.sql.hive.convertMetastoreParquet", "false") \  # ‚Üê NOUVEAU
    .enableHiveSupport() \
    .getOrCreate()
```

**Explication** :
- `spark.sql.hive.convertMetastoreParquet = false` : D√©sactive la conversion automatique
- Spark lit directement les fichiers Parquet sans passer par le metastore Hive
- **Pas de perte de fonctionnalit√©** : Les tables restent interrogeables via SQL

---

## ‚úÖ SOLUTION 2 : Recr√©er les tables avec DROP FORCE

**D√©j√† impl√©ment√© dans Notebook 05, cellule 4** :

```python
# D'abord supprimer compl√®tement le metastore
spark.sql(f"DROP TABLE IF EXISTS {table_name}")

# Puis recr√©er la table
spark.sql(create_sql)
```

---

## üöÄ √âTAPES √Ä SUIVRE

### 1. Red√©marrer le Notebook

Dans Jupyter Lab :
1. **Kernel** ‚Üí **Restart Kernel**
2. **Run** ‚Üí **Run All Cells**

### 2. V√©rifier les r√©sultats

La cellule de cr√©ation devrait afficher :

```
üì¶ Cr√©ation des tables externes...

  üóëÔ∏è  dim_temps - ancien metastore supprim√©
  ‚úÖ 1/6 - dim_temps cr√©√©e
  üóëÔ∏è  dim_patient - ancien metastore supprim√©
  ‚úÖ 2/6 - dim_patient cr√©√©e
  ...
  ‚úÖ 6/6 - fait_consultation cr√©√©e

‚úÖ Toutes les tables cr√©√©es !
```

### 3. Comptage des lignes

```
============================================================
  dim_temps                 :      4,748 lignes  ‚Üê ‚úÖ FIX√â
  dim_patient               :    100,000 lignes
  dim_diagnostic            :     15,490 lignes
  dim_professionnel         :  1,048,575 lignes
  dim_etablissement         :        200 lignes
  fait_consultation         :  1,027,157 lignes
============================================================
  TOTAL                     :  2,191,422 lignes
```

### 4. Test des requ√™tes

Les 5 tests SQL (consultations par ann√©e, diagnostics, etc.) devraient tous fonctionner.

---

## üîç DIAGNOSTIC DU PROBL√àME

### V√©rifier le sch√©ma Parquet vs Metastore

```python
# Lire directement le Parquet
df_parquet = spark.read.parquet("/home/jovyan/data/gold/dim_temps")
print("Sch√©ma PARQUET:")
df_parquet.printSchema()

# Lire via la table Hive
df_hive = spark.table("dim_temps")
print("\nSch√©ma METASTORE:")
df_hive.printSchema()
```

**Diff√©rence typique** :
```
Parquet : date_complete (DATE)
Metastore : date_complete (STRING)  ‚Üê Conflit
```

---

## üõ°Ô∏è PR√âVENTION FUTURE

### Option A : Toujours utiliser la config Spark

Dans **tous les notebooks** qui cr√©ent des tables Hive :

```python
spark = SparkSession.builder \
    .config("spark.sql.hive.convertMetastoreParquet", "false") \
    .enableHiveSupport() \
    .getOrCreate()
```

### Option B : D√©finir la config globalement

Dans `docker-compose.yml` - service `spark-master` :

```yaml
environment:
  - SPARK_CONF_spark.sql.hive.convertMetastoreParquet=false
```

Puis red√©marrer :
```bash
docker-compose restart spark-master spark-worker
```

---

## üìä IMPACT SUR SUPERSET

### Aucun impact n√©gatif

- Les tables restent **100% interrogeables** via SQL
- Superset se connecte via **Thrift Server** ‚Üí fonctionne normalement
- Les performances sont **identiques** (voire l√©g√®rement meilleures car pas de conversion)

### Test de connexion Superset

Une fois les tables recr√©√©es, dans Superset SQL Lab :

```sql
SELECT
    t.annee,
    COUNT(*) as nb_consultations
FROM fait_consultation f
JOIN dim_temps t ON f.id_temps = t.id_temps
GROUP BY t.annee
ORDER BY t.annee
```

‚úÖ **R√©sultat attendu** : 9 lignes (2015-2023)

---

## ‚ùì FAQ

### Q1 : Pourquoi ce probl√®me appara√Æt maintenant ?

**R** : Les notebooks 01-02-03 cr√©ent les fichiers Parquet Gold avec un sch√©ma strict (types Python/Pandas ‚Üí Parquet). Quand on cr√©e des tables Hive **apr√®s**, il peut y avoir des incompatibilit√©s de typage (DATE vs STRING, INT vs LONG, etc.).

### Q2 : Est-ce que √ßa affecte les notebooks 01-03 ?

**R** : Non, ils utilisent `spark.read.parquet()` directement, pas de metastore Hive.

### Q3 : Faut-il refaire tous les notebooks ?

**R** : Non, juste **red√©marrer et relancer le Notebook 05** avec les corrections.

### Q4 : Les donn√©es sont-elles perdues ?

**R** : **NON** ! Les fichiers Parquet dans `/home/jovyan/data/gold/` sont intacts. On recr√©e juste les **m√©tadonn√©es** (metastore) qui pointent vers ces fichiers.

---

## ‚úÖ VALIDATION FINALE

**Checklist apr√®s fix** :

- [ ] Notebook 05 red√©marr√© et ex√©cut√© sans erreur
- [ ] 6 tables cr√©√©es avec succ√®s
- [ ] Comptage affiche ~2.2M lignes total
- [ ] Test 1 (consultations par ann√©e) fonctionne
- [ ] Connexion Superset teste avec succ√®s
- [ ] SQL Lab ex√©cute une requ√™te de test

---

## üéØ CONCLUSION

Ce probl√®me est **normal** et **facilement r√©solu** avec la configuration `spark.sql.hive.convertMetastoreParquet=false`.

**Les modifications appliqu√©es** :
1. ‚úÖ Configuration Spark dans Notebook 05 (cellule 2)
2. ‚úÖ DROP TABLE avant CREATE pour forcer la recr√©ation (cellule 4)

**Workflow E2E toujours 100% op√©rationnel** :
```
CSV/PostgreSQL ‚Üí Bronze ‚Üí Silver ‚Üí Gold ‚Üí Spark SQL ‚Üí Superset ‚úÖ
```

**Prochaine √©tape** : Une fois Notebook 05 valid√© ‚Üí Configurer Superset (GUIDE_DEMARRAGE_RAPIDE_SUPERSET.md)
