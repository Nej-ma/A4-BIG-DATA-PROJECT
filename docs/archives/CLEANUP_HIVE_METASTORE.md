# ğŸ§¹ NETTOYAGE HIVE METASTORE

## ProblÃ¨me

Tu as exÃ©cutÃ© le Notebook 05 **avant** mes corrections, donc le metastore Hive a enregistrÃ© des schÃ©mas conflictuels.

**Erreur actuelle** :
```
Column in converted table has different data type with source Hive table's.
```

---

## âœ… SOLUTION RAPIDE

### Option 1 : Via Notebook 05 (RECOMMANDÃ‰)

**Le notebook corrigÃ© nettoie automatiquement**, mais il faut le relancer avec Kernel Restart :

1. Ouvrir http://localhost:8888
2. **notebooks/05_Setup_Superset.ipynb**
3. **Kernel** â†’ **Restart Kernel** (important !)
4. **Run** â†’ **Run All Cells**

Le notebook va maintenant :
- âœ… Configurer `spark.sql.hive.convertMetastoreParquet=false`
- âœ… Supprimer les anciennes tables (`DROP TABLE IF EXISTS`)
- âœ… RecrÃ©er les tables avec le bon schÃ©ma

---

### Option 2 : Nettoyage manuel via beeline (si Option 1 ne marche pas)

**Connexion au Thrift Server** :

```bash
docker exec -it chu_spark_master beeline -u jdbc:hive2://localhost:10000/default
```

**Supprimer toutes les tables** :

```sql
DROP TABLE IF EXISTS dim_temps;
DROP TABLE IF EXISTS dim_patient;
DROP TABLE IF EXISTS dim_diagnostic;
DROP TABLE IF EXISTS dim_professionnel;
DROP TABLE IF EXISTS dim_etablissement;
DROP TABLE IF EXISTS fait_consultation;

-- VÃ©rifier
SHOW TABLES;
```

**Sortir** :
```
!quit
```

Puis relancer Notebook 05.

---

### Option 3 : Reset complet du metastore (NUCLEAR)

**Si vraiment rien ne fonctionne** :

```bash
# ArrÃªter Spark
docker exec chu_spark_master bash -c '$SPARK_HOME/sbin/stop-thriftserver.sh'

# Supprimer le metastore Hive (Derby DB)
docker exec chu_spark_master bash -c 'rm -rf /tmp/spark-warehouse /tmp/metastore_db'

# RedÃ©marrer Thrift Server
docker exec chu_spark_master bash -c '$SPARK_HOME/sbin/start-thriftserver.sh --master spark://spark-master:7077 --hiveconf hive.server2.thrift.port=10000 --hiveconf hive.server2.thrift.bind.host=0.0.0.0'

# Attendre 10 secondes
sleep 10
```

Puis relancer Notebook 05.

---

## ğŸ¯ Ã‰TAPES DÃ‰TAILLÃ‰ES (Option 1 recommandÃ©e)

### 1. Restart Kernel Jupyter

**TRÃˆS IMPORTANT** : Il faut redÃ©marrer le kernel pour que la nouvelle config Spark soit prise en compte.

Dans Jupyter :
1. Ouvrir **05_Setup_Superset.ipynb**
2. **Kernel** â†’ **Restart Kernel** (popup â†’ OK)
3. **Ne pas** juste Re-run, vraiment **Restart** !

### 2. Run All Cells

**Run** â†’ **Run All Cells**

Tu devrais voir :

```
âœ… Spark 3.5.0 dÃ©marrÃ© avec support Hive
âœ… spark.sql.hive.convertMetastoreParquet = false (fix schÃ©ma)

ğŸ“¦ CrÃ©ation des tables externes...

  ğŸ—‘ï¸  dim_temps - ancien metastore supprimÃ©
  âœ… 1/6 - dim_temps crÃ©Ã©e
  ğŸ—‘ï¸  dim_patient - ancien metastore supprimÃ©
  âœ… 2/6 - dim_patient crÃ©Ã©e
  ğŸ—‘ï¸  dim_diagnostic - ancien metastore supprimÃ©
  âœ… 3/6 - dim_diagnostic crÃ©Ã©e
  ğŸ—‘ï¸  dim_professionnel - ancien metastore supprimÃ©
  âœ… 4/6 - dim_professionnel crÃ©Ã©e
  ğŸ—‘ï¸  dim_etablissement - ancien metastore supprimÃ©
  âœ… 5/6 - dim_etablissement crÃ©Ã©e
  ğŸ—‘ï¸  fait_consultation - ancien metastore supprimÃ©
  âœ… 6/6 - fait_consultation crÃ©Ã©e

âœ… Toutes les tables crÃ©Ã©es !
```

### 3. VÃ©rifier le comptage

```
ğŸ“Š COMPTAGE DES LIGNES
============================================================
  dim_temps                 :      4,748 lignes  â† âœ… PLUS D'ERREUR
  dim_patient               :    100,000 lignes
  dim_diagnostic            :     15,490 lignes
  dim_professionnel         :  1,048,575 lignes
  dim_etablissement         :        200 lignes
  fait_consultation         :  1,027,157 lignes
============================================================
  TOTAL                     :  2,191,422 lignes

âœ… Toutes les tables sont accessibles !
```

### 4. VÃ©rifier les tests SQL

Les 5 tests (TEST 1 Ã  TEST 5) doivent tous s'exÃ©cuter sans erreur.

**TEST 1 attendu** :
```
+-----+----------------+----------------+
|annee|nb_consultations|patients_uniques|
+-----+----------------+----------------+
|2015 |33896           |28581           |
|2016 |184308          |85272           |
|2017 |133403          |74201           |
...
```

---

## ğŸ” DIAGNOSTIC

### VÃ©rifier que la config Spark est appliquÃ©e

Dans le Notebook 05, cellule 2, aprÃ¨s exÃ©cution :

```python
# Ajouter cette cellule temporaire pour vÃ©rifier :
print(spark.conf.get("spark.sql.hive.convertMetastoreParquet"))
# Doit afficher : false
```

### VÃ©rifier que les tables sont DROP avant CREATE

Dans le Notebook 05, tu dois voir dans les logs :

```
ğŸ—‘ï¸  dim_temps - ancien metastore supprimÃ©
```

Si tu vois `â„¹ï¸  dim_temps - pas de metastore existant`, c'est normal la premiÃ¨re fois.

---

## âŒ SI ERREUR PERSISTE

### Erreur : "Connection refused to Thrift Server"

**Cause** : Thrift Server crashÃ© ou pas dÃ©marrÃ©

**Fix** :
```bash
# VÃ©rifier si le process tourne
docker exec chu_spark_master ps aux | grep -i thrift

# Si rien, redÃ©marrer
docker exec chu_spark_master bash -c '$SPARK_HOME/sbin/start-thriftserver.sh --master spark://spark-master:7077 --hiveconf hive.server2.thrift.port=10000'

# Attendre 10 secondes
sleep 10

# Relancer Notebook 05
```

### Erreur : "Table already exists"

**Cause** : DROP TABLE n'a pas fonctionnÃ©

**Fix** :
```python
# Dans Jupyter, crÃ©er une nouvelle cellule et exÃ©cuter :
spark.sql("DROP TABLE IF EXISTS dim_temps")
spark.sql("DROP TABLE IF EXISTS dim_patient")
spark.sql("DROP TABLE IF EXISTS dim_diagnostic")
spark.sql("DROP TABLE IF EXISTS dim_professionnel")
spark.sql("DROP TABLE IF EXISTS dim_etablissement")
spark.sql("DROP TABLE IF EXISTS fait_consultation")

# Puis relancer cellule 4 (crÃ©ation des tables)
```

---

## âœ… VALIDATION

**Checklist aprÃ¨s nettoyage** :

- [ ] Notebook 05 Kernel restarted
- [ ] Cellule 2 affiche : `spark.sql.hive.convertMetastoreParquet = false`
- [ ] Cellule 4 affiche : `âœ… 1/6 - dim_temps crÃ©Ã©e` (sans erreur)
- [ ] Cellule de comptage affiche : `dim_temps : 4,748 lignes` (sans âŒ)
- [ ] TEST 1 s'exÃ©cute sans erreur et affiche 9 lignes

---

## ğŸ¯ RÃ‰SUMÃ‰

**Le problÃ¨me** : Metastore Hive a enregistrÃ© un schÃ©ma conflictuel lors de la premiÃ¨re exÃ©cution (avant corrections).

**La solution** : Restart Kernel + Run All pour que :
1. Config `convertMetastoreParquet=false` soit appliquÃ©e
2. DROP TABLE supprime les anciens metastores
3. CREATE TABLE recrÃ©e avec le bon schÃ©ma

**Action immÃ©diate** :
```
Jupyter â†’ 05_Setup_Superset.ipynb
â†’ Kernel â†’ Restart Kernel
â†’ Run â†’ Run All Cells
âœ… VÃ©rifier comptage dim_temps sans erreur
```

**Temps estimÃ©** : 2 minutes

Bonne chance ! ğŸš€
