# ğŸš€ GUIDE DÃ‰MARRAGE RAPIDE - SUPERSET

**Temps estimÃ©** : 10 minutes

---

## ğŸ“‹ CHECKLIST PRÃ‰ALABLE

Avant de commencer, vÃ©rifier que :

- âœ… Docker containers en cours d'exÃ©cution :
  ```bash
  docker ps
  ```
  Vous devez voir `chu_superset` et `chu_spark_master` avec status `Up`

- âœ… Notebooks 01-02-03 exÃ©cutÃ©s avec succÃ¨s (donnÃ©es Gold crÃ©Ã©es)

- âœ… Spark Thrift Server dÃ©marrÃ© :
  ```bash
  docker exec chu_spark_master ps aux | grep -i thrift
  ```
  Si vide, dÃ©marrer avec :
  ```bash
  docker exec chu_spark_master bash -c '$SPARK_HOME/sbin/start-thriftserver.sh --master spark://spark-master:7077 --hiveconf hive.server2.thrift.port=10000 --hiveconf hive.server2.thrift.bind.host=0.0.0.0'
  ```

---

## ğŸ¯ Ã‰TAPE 1 : CrÃ©er les tables Spark SQL (2 min)

### Ouvrir Jupyter Lab

ğŸŒ http://localhost:8888

### ExÃ©cuter le notebook 05_Setup_Superset.ipynb

1. **notebooks/** â†’ **05_Setup_Superset.ipynb**
2. **Kernel** â†’ **Restart & Run All**
3. Attendre que toutes les cellules soient exÃ©cutÃ©es (~1 min)

### âœ… VÃ©rifier le rÃ©sultat

La derniÃ¨re cellule doit afficher :
```
âœ… Toutes les tables sont accessibles !

  dim_temps                 :      4,748 lignes
  dim_patient               :    100,000 lignes
  dim_diagnostic            :        100 lignes
  dim_professionnel         :    100,000 lignes
  dim_etablissement         :      3,500 lignes
  fait_consultation         :  1,027,157 lignes
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL                     :  1,235,505 lignes
```

---

## ğŸ¨ Ã‰TAPE 2 : Configurer Superset (5 min)

### 2.1 Ouvrir Superset

ğŸŒ http://localhost:8088

**Identifiants** :
- Username: `admin`
- Password: `admin`

### 2.2 Ajouter la connexion Database

1. Cliquer sur **âš™ï¸ Settings** (en haut Ã  droite)
2. **Database Connections**
3. **+ DATABASE** (bouton bleu)

### 2.3 Configurer la connexion

**MÃ©thode recommandÃ©e** : SQLAlchemy URI

1. SÃ©lectionner **"SUPPORTED DATABASES"** â†’ **"Apache Spark SQL"**
2. Onglet **"SQLALCHEMY URI"**
3. Copier-coller cette URI :
   ```
   hive://spark-master:10000/default
   ```
4. **Display Name** : `CHU_Gold_Layer`
5. Cocher :
   - âœ… Expose database in SQL Lab
   - âœ… Allow CREATE TABLE AS
   - âœ… Allow DML
6. Cliquer **TEST CONNECTION**
7. âœ… Si "Connection looks good!" â†’ Cliquer **CONNECT**

### âš ï¸ Si erreur de connexion

**Erreur** : "Could not connect to database"

**Solutions** :

1. **VÃ©rifier que Thrift Server tourne** :
   ```bash
   docker exec chu_spark_master ps aux | grep thrift
   ```

2. **Essayer une URI alternative** :
   ```
   hive://spark-master:10000/default?auth=NOSASL
   ```

3. **RedÃ©marrer Thrift Server** :
   ```bash
   docker exec chu_spark_master bash -c '$SPARK_HOME/sbin/stop-thriftserver.sh'
   docker exec chu_spark_master bash -c '$SPARK_HOME/sbin/start-thriftserver.sh --master spark://spark-master:7077'
   ```

---

## ğŸ“Š Ã‰TAPE 3 : Tester SQL Lab (1 min)

### 3.1 Ouvrir SQL Lab

Menu principal â†’ **SQL Lab** â†’ **SQL Editor**

### 3.2 SÃ©lectionner la base de donnÃ©es

Dans la barre supÃ©rieure :
- **DATABASE** : `CHU_Gold_Layer`
- **SCHEMA** : `default`

### 3.3 ExÃ©cuter une requÃªte test

Copier-coller dans l'Ã©diteur :

```sql
SELECT
    t.annee,
    COUNT(*) as nb_consultations,
    COUNT(DISTINCT f.id_patient) as patients_uniques
FROM fait_consultation f
JOIN dim_temps t ON f.id_temps = t.id_temps
GROUP BY t.annee
ORDER BY t.annee
```

Cliquer **RUN** (ou Ctrl+EntrÃ©e)

### âœ… RÃ©sultat attendu

```
annee | nb_consultations | patients_uniques
------|------------------|------------------
2015  |     33,896       |     28,581
2016  |    184,308       |     85,272
2017  |    133,403       |     74,201
...
```

**Si vous voyez ces rÃ©sultats â†’ PARFAIT !** Superset est connectÃ© au Data Lakehouse.

---

## ğŸ¨ Ã‰TAPE 4 : CrÃ©er votre premier graphique (2 min)

### 4.1 CrÃ©er un Dataset

1. Menu **Data** â†’ **Datasets**
2. **+ DATASET**
3. **Database** : `CHU_Gold_Layer`
4. **Schema** : `default`
5. **Table** : `fait_consultation`
6. **ADD**

### 4.2 CrÃ©er un graphique

1. Menu **Charts** â†’ **+ CHART**
2. **Dataset** : `fait_consultation`
3. **Chart Type** : **Big Number with Trendline**
4. **Configuration** :
   - **METRIC** : `COUNT(*)`
   - **TIME COLUMN** : (laisser vide pour l'instant)
5. Cliquer **UPDATE CHART**

### âœ… RÃ©sultat

Vous devriez voir : **1,027,157** (nombre total de consultations)

### 4.3 Sauvegarder

1. Cliquer **SAVE** (en haut Ã  droite)
2. **Chart Name** : `Total Consultations`
3. **Add to Dashboard** : CrÃ©er un nouveau dashboard "CHU Overview"
4. **SAVE & GO TO DASHBOARD**

---

## ğŸ“ˆ Ã‰TAPE 5 : Exemples de visualisations rapides

### 5.1 Consultations par annÃ©e (Bar Chart)

**SQL personnalisÃ©** (Data â†’ SQL Lab â†’ **Save as Dataset**) :

```sql
SELECT
    t.annee,
    COUNT(*) as nb_consultations
FROM fait_consultation f
JOIN dim_temps t ON f.id_temps = t.id_temps
GROUP BY t.annee
ORDER BY t.annee
```

**Chart Type** : Bar Chart
- **X-AXIS** : `annee`
- **METRICS** : `SUM(nb_consultations)`

### 5.2 Top Diagnostics (Pie Chart)

```sql
SELECT
    d.categorie,
    CASE d.categorie
        WHEN 'A' THEN 'Maladies infectieuses'
        WHEN 'C' THEN 'Tumeurs'
        WHEN 'I' THEN 'Cardiovasculaires'
        WHEN 'J' THEN 'Respiratoires'
        WHEN 'M' THEN 'Musculo-squelettiques'
        WHEN 'O' THEN 'Grossesse'
        WHEN 'S' THEN 'Traumatismes'
        ELSE 'Autres'
    END as libelle,
    COUNT(*) as nb_consultations
FROM fait_consultation f
JOIN dim_diagnostic d ON f.code_diag = d.code_diag
WHERE d.categorie IS NOT NULL
GROUP BY d.categorie
ORDER BY nb_consultations DESC
LIMIT 8
```

**Chart Type** : Pie Chart
- **DIMENSIONS** : `libelle`
- **METRIC** : `SUM(nb_consultations)`

### 5.3 RÃ©partition Homme/Femme (Donut Chart)

```sql
SELECT
    p.sexe,
    COUNT(*) as nb_consultations
FROM fait_consultation f
JOIN dim_patient p ON f.id_patient = p.id_patient
GROUP BY p.sexe
```

**Chart Type** : Pie Chart (ou Donut)
- **DIMENSIONS** : `sexe`
- **METRIC** : `SUM(nb_consultations)`

---

## ğŸ¯ Ã‰TAPE 6 : Dashboard complet (optionnel)

Voir **TUTORIEL_SUPERSET.md** pour crÃ©er un dashboard avancÃ© avec :

- ğŸ“Š KPIs (Total consultations, Patients, CoÃ»t moyen)
- ğŸ“ˆ Ã‰volutions temporelles
- ğŸ—ºï¸ Cartes gÃ©ographiques (par rÃ©gion)
- ğŸ¥ Top Ã©tablissements
- ğŸ‘¨â€âš•ï¸ Top spÃ©cialitÃ©s
- ğŸ“‹ Tableaux dÃ©taillÃ©s

---

## âŒ TROUBLESHOOTING

### ProblÃ¨me 1 : "No database found"

**Cause** : Connexion database pas configurÃ©e

**Solution** : Reprendre Ã‰tape 2.2

---

### ProblÃ¨me 2 : "Table not found"

**Cause** : Tables Spark SQL pas crÃ©Ã©es

**Solution** : ExÃ©cuter Notebook 05_Setup_Superset.ipynb (Ã‰tape 1)

---

### ProblÃ¨me 3 : "Connection timeout"

**Cause** : Thrift Server pas dÃ©marrÃ©

**Solution** :
```bash
docker exec chu_spark_master bash -c '$SPARK_HOME/sbin/start-thriftserver.sh --master spark://spark-master:7077 --hiveconf hive.server2.thrift.port=10000'
```

Attendre 10 secondes puis tester la connexion.

---

### ProblÃ¨me 4 : Tables vides (0 lignes)

**Cause** : Partitions pas rÃ©parÃ©es pour `fait_consultation`

**Solution** : Dans SQL Lab, exÃ©cuter :
```sql
MSCK REPAIR TABLE fait_consultation;
```

---

### ProblÃ¨me 5 : Superset ne dÃ©marre pas

**Solution** :
```bash
docker-compose restart superset
docker logs chu_superset --tail 50
```

---

## âœ… CHECKLIST FINALE

Avant de dÃ©clarer le workflow complet validÃ© :

- [ ] Superset accessible sur http://localhost:8088
- [ ] Connexion `CHU_Gold_Layer` crÃ©Ã©e et testÃ©e
- [ ] SQL Lab exÃ©cute des requÃªtes avec succÃ¨s
- [ ] Au moins 1 dataset crÃ©Ã© (fait_consultation)
- [ ] Au moins 1 graphique crÃ©Ã©
- [ ] Au moins 1 dashboard crÃ©Ã©

---

## ğŸ“š POUR ALLER PLUS LOIN

### Documentation complÃ¨te

Voir **TUTORIEL_SUPERSET.md** pour :
- CrÃ©ation des 6 datasets (dimensions + fait)
- 15+ exemples de visualisations
- Dashboards avancÃ©s avec filtres
- RequÃªtes mÃ©tier (taux hospitalisation, satisfaction, etc.)
- Export PDF et partage

### Workflow complet E2E

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CSV Files    â”‚ â”€â”€â”
â”‚ PostgreSQL   â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Jupyter Notebook â”‚
         â”‚ 01_Extract       â”‚ â”€â”€â–º Bronze Layer (Parquet)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 02_Transform     â”‚ â”€â”€â–º Silver Layer (Cleaned + RGPD)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 03_Transform     â”‚ â”€â”€â–º Gold Layer (Star Schema)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 05_Setup         â”‚ â”€â”€â–º Spark SQL Tables
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Superset         â”‚ â”€â”€â–º Dashboards & Analytics
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ğŸ“ Projet 100% fonctionnel pour Livrable 2 !**

---

## ğŸ†˜ AIDE

Si problÃ¨me persistant :

1. VÃ©rifier les logs :
   ```bash
   docker logs chu_superset --tail 100
   docker logs chu_spark_master --tail 100
   ```

2. VÃ©rifier les tables Spark :
   ```bash
   docker exec chu_spark_master spark-sql -e "SHOW TABLES"
   ```

3. Tester Thrift Server manuellement :
   ```bash
   docker exec -it chu_spark_master beeline -u jdbc:hive2://localhost:10000/default
   ```

Bonne chance ! ğŸš€
