# ğŸ¯ Ã‰TAPES FINALES - Superset fonctionnel

**Fix appliquÃ©** : dim_temps n'est plus partitionnÃ© (incompatibilitÃ© Hive)

---

## âœ… Ã‰TAPE 1 : RegÃ©nÃ©rer Gold Layer (5 min)

### 1.1 ExÃ©cuter Notebook 03

**Jupyter** : http://localhost:8888

1. Ouvrir **03_Transform_Gold_STAR_SCHEMA.ipynb**
2. **Kernel** â†’ **Restart Kernel**
3. **Run** â†’ **Run All Cells**

**Attendre** : ~3-4 minutes

**VÃ©rification** : La cellule 4 (dim_temps) doit afficher :
```
ğŸ’¾ SauvegardÃ©: /home/jovyan/data/gold/dim_temps (sans partitionnement)
   â„¹ï¸  ChangÃ©: Pas de partitionnement pour compatibilitÃ© Hive/Superset
```

---

## âœ… Ã‰TAPE 2 : CrÃ©er tables Hive (2 min)

### 2.1 ExÃ©cuter Notebook 05

1. Ouvrir **05_Setup_Superset.ipynb**
2. **Kernel** â†’ **Restart Kernel**
3. **Run** â†’ **Run All Cells**

**RÃ©sultat attendu** :

```
âœ… Spark 3.5.0 dÃ©marrÃ© avec support Hive
âœ… spark.sql.hive.convertMetastoreParquet = false (fix schÃ©ma)

ğŸ“¦ CrÃ©ation des tables externes...

  ğŸ—‘ï¸  dim_temps - ancien metastore supprimÃ©
  âœ… 1/6 - dim_temps crÃ©Ã©e (SANS partitionnement)  â† FIX
  ...
  âœ… 6/6 - fait_consultation crÃ©Ã©e

âœ… Toutes les tables crÃ©Ã©es !

ğŸ”§ RÃ©paration des partitions de fait_consultation...
âœ… Partitions rÃ©parÃ©es !
ğŸ“Š 90 partitions trouvÃ©es

ğŸ“Š COMPTAGE DES LIGNES
============================================================
  dim_temps                 :      4,748 lignes  â† âœ… PLUS D'ERREUR
  dim_patient               :    100,000 lignes
  dim_diagnostic            :     15,490 lignes
  dim_professionnel         :  1,048,575 lignes
  dim_etablissement         :        200 lignes
  fait_consultation         :  1,027,157 lignes
============================================================
  TOTAL                     :  2,191,422 lignes

âœ… Toutes les tables sont accessibles !

ğŸ” TEST 1 : Consultations par annÃ©e

+-----+----------------+----------------+
|annee|nb_consultations|patients_uniques|
+-----+----------------+----------------+
|2015 |33896           |28581           |
|2016 |184308          |85272           |
...
```

---

## âœ… Ã‰TAPE 3 : Configurer Superset (5 min)

### 3.1 Attendre Superset (si redÃ©marrÃ©)

```bash
docker logs chu_superset --tail 20
```

Attendre : "Starting Superset server"

### 3.2 Connexion

**URL** : http://localhost:8088
**Login** : `admin` / `admin`

### 3.3 Ajouter Database

1. **Settings** âš™ï¸ â†’ **Database Connections**
2. **+ DATABASE**
3. **SUPPORTED DATABASES** â†’ **Apache Spark SQL**
4. **SQLAlchemy URI** :
   ```
   hive://spark-master:10000/default
   ```
5. **Display Name** : `CHU_Gold_Layer`
6. **ADVANCED** â†’ Other â†’ Cocher :
   - âœ… Expose database in SQL Lab
   - âœ… Allow CREATE TABLE AS
7. **TEST CONNECTION** â†’ âœ… "Connection looks good!"
8. **CONNECT**

---

## âœ… Ã‰TAPE 4 : Tester SQL Lab (1 min)

1. **SQL Lab** â†’ **SQL Editor**
2. **DATABASE** : `CHU_Gold_Layer`
3. **SCHEMA** : `default`

**RequÃªte test** :

```sql
SELECT
    t.annee,
    COUNT(*) as nb_consultations,
    COUNT(DISTINCT f.id_patient) as patients_uniques
FROM fait_consultation f
JOIN dim_temps t ON f.id_temps = t.id_temps
GROUP BY t.annee
ORDER BY t.annee
```

4. **RUN**

**RÃ©sultat attendu** : 9 lignes (2015-2023)

```
annee | nb_consultations | patients_uniques
------|------------------|------------------
2015  |     33,896       |     28,581
2016  |    184,308       |     85,272
...
```

âœ… **SI TU VOIS CES RÃ‰SULTATS â†’ WORKFLOW E2E VALIDÃ‰ !**

---

## âœ… Ã‰TAPE 5 : Dashboard (2 min)

### 5.1 CrÃ©er Dataset

1. **Data** â†’ **Datasets** â†’ **+ DATASET**
2. **Database** : `CHU_Gold_Layer`
3. **Schema** : `default`
4. **Table** : `fait_consultation`
5. **ADD**

### 5.2 CrÃ©er Graphique

1. **Charts** â†’ **+ CHART**
2. **Dataset** : `fait_consultation`
3. **Chart Type** : **Big Number**
4. **QUERY** â†’ **Metrics** : `COUNT(*)`
5. **UPDATE CHART**

âœ… **RÃ©sultat** : **1,027,157**

### 5.3 CrÃ©er Dashboard

1. **SAVE** (en haut Ã  droite)
2. **Chart Name** : `Total Consultations CHU`
3. **Add to Dashboard** : **Create new dashboard**
   - Name: `CHU Overview - Livrable 2`
4. **SAVE & GO TO DASHBOARD**

âœ… **TON DASHBOARD SUPERSET EST CRÃ‰Ã‰ !**

---

## ğŸ“Š CORRECTIONS APPLIQUÃ‰ES

### Fix 1 : Notebook 03 - dim_temps sans partitionnement

**ProblÃ¨me** : dim_temps partitionnÃ© par `annee` cause "Path is a directory" avec Hive

**Solution** : Suppression de `.partitionBy("annee")`

**Avant** :
```python
dim_temps.write \
    .mode("overwrite") \
    .partitionBy("annee") \
    .parquet(f"{GOLD_OUTPUT}/dim_temps")
```

**AprÃ¨s** :
```python
dim_temps.write \
    .mode("overwrite") \
    .parquet(f"{GOLD_OUTPUT}/dim_temps")
```

### Fix 2 : Notebook 05 - dim_temps sans PARTITIONED BY

**ProblÃ¨me** : Table Hive dÃ©clarÃ©e avec `PARTITIONED BY (annee INT)` mais fichiers non partitionnÃ©s

**Solution** : Suppression de la clause `PARTITIONED BY`

**Avant** :
```sql
CREATE EXTERNAL TABLE dim_temps (...)
PARTITIONED BY (annee INT)
STORED AS PARQUET ...
```

**AprÃ¨s** :
```sql
CREATE EXTERNAL TABLE dim_temps (...)
STORED AS PARQUET ...
```

### Fix 3 : Notebook 05 - Tests avec tables Hive natives

**Avant** : Tests utilisaient des vues temporaires `_tmp`

**AprÃ¨s** : Tests utilisent directement les tables Hive (plus rapide, compatible Superset)

---

## ğŸ¯ VALIDATION FINALE

**Checklist** :

- [ ] Notebook 03 exÃ©cutÃ© (dim_temps sans partitionnement)
- [ ] Notebook 05 exÃ©cutÃ© (6 tables crÃ©Ã©es)
- [ ] Comptage dim_temps : 4,748 lignes (sans âŒ)
- [ ] Test SQL Notebook 05 : 9 lignes (2015-2023)
- [ ] Superset connexion CHU_Gold_Layer âœ…
- [ ] SQL Lab requÃªte test : 9 lignes
- [ ] Dataset fait_consultation crÃ©Ã©
- [ ] Graphique Big Number : 1,027,157
- [ ] Dashboard CHU Overview crÃ©Ã©

---

## ğŸ“ WORKFLOW E2E COMPLET

```
Sources (CSV 25M + PostgreSQL)
    â†“
Bronze Layer (17 tables, 29M lignes) - Notebook 01 âœ…
    â†“
Silver Layer (12 tables, RGPD) - Notebook 02 âœ…
    â†“
Gold Layer (8 tables, Star Schema) - Notebook 03 âœ… FIX
    â”œâ”€ dim_temps (SANS partitionnement) â† FIX
    â”œâ”€ dim_patient
    â”œâ”€ dim_diagnostic (+ categorie CIM-10)
    â”œâ”€ dim_professionnel
    â”œâ”€ dim_etablissement (+ region/dÃ©partement)
    â”œâ”€ fait_consultation (partitionnÃ© annee/mois)
    â”œâ”€ fait_deces
    â””â”€ fait_satisfaction
    â†“
Benchmarks (6 requÃªtes < 16s) - Notebook 04 âœ…
    â†“
Spark SQL Tables (6 tables Hive) - Notebook 05 âœ… FIX
    â”œâ”€ dim_temps (SANS partitionnement) â† FIX
    â””â”€ fait_consultation (partitionnÃ© annee/mois)
    â†“
Thrift Server (port 10000) âœ…
    â†“
Superset (PyHive installÃ©) âœ…
    â”œâ”€ Connexion CHU_Gold_Layer
    â”œâ”€ SQL Lab
    â”œâ”€ Datasets
    â”œâ”€ Charts
    â””â”€ Dashboards âœ…
```

**STATUT FINAL** : âœ… 100% OpÃ©rationnel

---

## ğŸš€ ACTION IMMÃ‰DIATE

1. **Notebook 03** : Kernel â†’ Restart â†’ Run All (5 min)
2. **Notebook 05** : Kernel â†’ Restart â†’ Run All (2 min)
3. **Superset** : Connexion + SQL Lab + Dashboard (5 min)

**Total** : 12 minutes

**Puis** : ğŸ‰ Projet 100% terminÃ© pour Livrable 2 !

Vas-y maintenant ! ğŸ’ª
