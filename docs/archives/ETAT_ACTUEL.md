# ğŸ“Š Ã‰TAT ACTUEL DU PROJET - CHU Data Lakehouse

**Date** : 21 Octobre 2025
**Livrable** : Livrable 2 - ModÃ¨le physique et optimisation

---

## âœ… CE QUI EST PRÃŠT ET FONCTIONNE

### 1. Infrastructure Docker (100% opÃ©rationnelle)

| Service | URL | Login | Status |
|---------|-----|-------|--------|
| **PostgreSQL** | localhost:5432 | admin / admin123 | âœ… 100K patients, 1M consultations |
| **MinIO Console** | http://localhost:9001 | minioadmin / minioadmin123 | âœ… Buckets: lakehouse, warehouse |
| **Jupyter Lab** | http://localhost:8888 | Token: admin123 | âœ… PrÃªt avec Spark |
| **Spark Master UI** | http://localhost:8081 | - | âœ… Running |
| **Airflow** | http://localhost:8080 | admin / admin123 | âœ… CorrigÃ© |
| **Superset** | http://localhost:8088 | admin / admin123 | âœ… Running |
| **PgAdmin** | http://localhost:5050 | admin@chu.fr / admin123 | âœ… Running |

### 2. Code crÃ©Ã©

```
spark/jobs/
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ spark_utils.py                    âœ… Fonctions utilitaires Spark
â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ ingest_postgres_to_bronze.py      âœ… PostgreSQL â†’ MinIO
â”‚   â””â”€â”€ ingest_csv_to_bronze.py           âœ… CSV â†’ MinIO
â”œâ”€â”€ test_connections.py                   âœ… Script de test
â””â”€â”€ (silver/, gold/, performance/)        â³ Ã€ crÃ©er

docs/livrable2/
â”œâ”€â”€ modele_dimensionnel.md                âœ… Star Schema documentÃ©
â””â”€â”€ README.md                             âœ… Guide complet
```

### 3. DonnÃ©es disponibles

**PostgreSQL (restaurÃ©)** :
- 100,000 patients
- 1,027,157 consultations
- 13 tables au total

**CSV disponibles** :
- DÃ©cÃ¨s (~300K lignes)
- Satisfaction (2014-2019, multiple fichiers)
- Ã‰tablissements de santÃ© (~30K)
- Hospitalisations

---

## ğŸ¯ CE QUE VOUS DEVEZ FAIRE MAINTENANT

### OPTION 1 : Tester que tout fonctionne (RECOMMANDÃ‰)

#### A. VÃ©rifier MinIO
1. Ouvrez http://localhost:9001
2. Login: `minioadmin` / `minioadmin123`
3. Vous devriez voir 2 buckets : `lakehouse` et `warehouse`

#### B. Tester avec Jupyter
1. Ouvrez http://localhost:8888
2. Token: `admin123`
3. CrÃ©ez un nouveau notebook Python
4. Copiez-collez ce code :

```python
from pyspark.sql import SparkSession

# CrÃ©er session Spark
spark = SparkSession.builder.appName("Test").getOrCreate()

# Test PostgreSQL
jdbc_url = "jdbc:postgresql://chu_postgres:5432/healthcare_data"
props = {"user": "admin", "password": "admin123", "driver": "org.postgresql.Driver"}

df_patient = spark.read.jdbc(url=jdbc_url, table='"Patient"', properties=props)
print(f"âœ… Patients dans PostgreSQL: {df_patient.count():,}")
df_patient.show(5)

# Test Ã©criture locale (pas S3 pour l'instant)
df_test = spark.createDataFrame([(1, "Test")], ["id", "val"])
df_test.write.mode("overwrite").parquet("/home/jovyan/data/test_output")
print("âœ… Ã‰criture Parquet OK")
```

**RÃ©sultat attendu** :
```
âœ… Patients dans PostgreSQL: 100,000
âœ… Ã‰criture Parquet OK
```

---

### OPTION 2 : Lancer l'ingestion Bronze (si Option 1 fonctionne)

Dans Jupyter, exÃ©cutez :

```python
# Ingestion PostgreSQL â†’ MinIO
!python /opt/spark-apps/bronze/ingest_postgres_to_bronze.py
```

**Ce que Ã§a fait** :
- Lit les 13 tables de PostgreSQL
- Les sauvegarde en format Delta Lake dans MinIO
- Localisation: `s3a://lakehouse/bronze/postgres/`

**DurÃ©e estimÃ©e** : 5-10 minutes

---

## âš ï¸ PROBLÃˆMES CONNUS

### 1. Connexion S3A MinIO depuis Spark
**SymptÃ´me** : `IllegalArgumentException: hostname cannot be null`

**Cause** : Configuration Hadoop S3A

**Solution temporaire** :
- Utiliser Jupyter pour lire PostgreSQL
- Sauvegarder localement d'abord (`/home/jovyan/data/`)
- Puis copier manuellement vers MinIO

**Solution permanente** :
- Ajouter un fichier `core-site.xml` avec la config S3A
- Ou utiliser Airflow pour orchestrer (a accÃ¨s Ã  MinIO)

### 2. Spark Worker redÃ©marre
**SymptÃ´me** : `chu_spark_worker` en status "Restarting"

**Impact** : Aucun pour l'instant (Spark Master fonctionne en mode local)

**Solution** :
```bash
docker logs chu_spark_worker
docker compose restart spark-worker
```

---

## ğŸ“‹ PLAN D'ACTION POUR LE LIVRABLE 2

### Phase 1 : Ingestion Bronze (EN COURS)
- [ ] Tester connexion PostgreSQL âœ… (FAIT)
- [ ] Tester Ã©criture fichiers âœ… (FAIT)
- [ ] Corriger connexion S3A MinIO â³
- [ ] IngÃ©rer PostgreSQL â†’ Bronze
- [ ] IngÃ©rer CSV â†’ Bronze

### Phase 2 : Transformation Silver
- [ ] Script de nettoyage des donnÃ©es
- [ ] Validation des types
- [ ] DÃ©doublonnage
- [ ] Enrichissements

### Phase 3 : ModÃ¨le Gold (Star Schema)
- [ ] CrÃ©er dimensions (Patient, Temps, Diagnostic, etc.)
- [ ] CrÃ©er faits (Consultations, Hospitalisations, etc.)
- [ ] ImplÃ©menter partitionnement
- [ ] ImplÃ©menter bucketing

### Phase 4 : Performance
- [ ] CrÃ©er requÃªtes benchmark
- [ ] Mesurer temps SANS optimisation
- [ ] Mesurer temps AVEC optimisation
- [ ] GÃ©nÃ©rer graphiques
- [ ] RÃ©diger rapport

---

## ğŸ’¡ RECOMMANDATION

**Pour avancer rapidement** :

1. **Testez Option 1** (code Jupyter ci-dessus) pour vÃ©rifier que Spark fonctionne
2. **Si Ã§a marche**, on peut :
   - Soit corriger S3A ensemble
   - Soit passer directement Ã  crÃ©er le modÃ¨le Gold (plus important pour le livrable)
3. **Si Ã§a ne marche pas**, donnez-moi l'erreur exacte

**Question** : Voulez-vous que je vous aide Ã  :
- A) Corriger S3A pour que l'ingestion Bronze fonctionne ?
- B) Passer directement aux scripts Silver/Gold (plus important) ?
- C) CrÃ©er un notebook Jupyter complet avec tout le pipeline ?

Dites-moi ce qui vous bloque exactement et ce que vous voulez faire en prioritÃ© !
