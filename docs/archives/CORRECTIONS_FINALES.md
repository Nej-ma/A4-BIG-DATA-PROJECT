# üîß CORRECTIONS FINALES - Pipeline Complet

**Date** : 22 Octobre 2025

---

## ‚úÖ PROBL√àMES R√âSOLUS

### 1. Ajout departements-francais.csv ‚úÖ
- Copi√© dans `/DATA_2024/departements-francais.csv`
- Ajout√© cellule dans Notebook 01 pour extraction

### 2. Donn√©es d√©plac√©es vers lakehouse ‚úÖ
- **Annul√©** : Remettre dans `/home/jovyan/data/`
- Raison : Les notebooks pointent vers `/home/jovyan/data/`, pas `/home/jovyan/data/lakehouse/`

---

## ‚ùå PROBL√àMES √Ä CORRIGER

### 1. Notebook 04 - Erreur `categorie` manquante

**Erreur** :
```
AnalysisException: A column or function parameter with name `d`.`categorie` cannot be resolved.
Did you mean one of the following? [`d`.`code_diag`]
```

**Cause** :
La table `dim_diagnostic` n'a que 2 colonnes :
- `code_diag`
- `libelle`

Mais la requ√™te SQL utilise `d.categorie` qui n'existe pas.

**Solution** :
Ajouter une colonne `categorie` dans `dim_diagnostic` en extrayant la premi√®re lettre du code :
```python
# Dans Notebook 03, cellule dim_diagnostic
dim_diagnostic = df_diagnostic_silver.select(
    col("Code_diag").alias("code_diag"),
    col("Diagnostic").alias("libelle"),
    # Ajouter cat√©gorie (premi√®re lettre du code)
    col("Code_diag").substr(1, 1).alias("categorie")
).dropDuplicates(["code_diag"])
```

**Cat√©gories CIM-10** :
- A : Maladies infectieuses
- B : Maladies infectieuses (suite)
- C : Tumeurs malignes
- D : Tumeurs b√©nignes
- E : Maladies endocriniennes
- F : Troubles mentaux
- G : Maladies du syst√®me nerveux
- etc.

---

### 2. Notebook 03 - Enrichir dim_etablissement avec d√©partements

**Objectif** :
Ajouter les colonnes r√©gion/d√©partement √† `dim_etablissement` via jointure avec `departements`.

**Solution** :
```python
# Lire d√©partements depuis Bronze
df_dept = spark.read.parquet(f"{SILVER_BASE}/../bronze/csv/departements")

# Extraire code d√©partement depuis code postal (2 premiers chiffres)
from pyspark.sql.functions import substring

dim_etablissement = dim_etablissement.withColumn(
    "code_departement",
    substring(col("code_postal"), 1, 2)
)

# Jointure avec d√©partements
dim_etablissement_enrichi = dim_etablissement.join(
    df_dept.select(
        col("num_departement"),
        col("libelle_departement"),
        col("libelle_region"),
        col("abv_region")
    ),
    dim_etablissement["code_departement"] == df_dept["num_departement"],
    "left"
)
```

---

## üöÄ PLAN D'ACTION

### √âtape 1 : Fix Notebook 03 (dim_diagnostic + categorie)

**Modifier cellule 6** (dim_diagnostic) :
```python
dim_diagnostic = df_diagnostic_silver.select(
    col("Code_diag").alias("code_diag"),
    col("Diagnostic").alias("libelle"),
    col("Code_diag").substr(1, 1).alias("categorie")  # ‚Üê AJOUT
).dropDuplicates(["code_diag"])
```

---

### √âtape 2 : Fix Notebook 03 (dim_etablissement + d√©partements)

**Modifier cellule 8** (dim_etablissement) :
```python
# Lire √©tablissements
df_etab_silver = spark.read.parquet(f"{SILVER_BASE}/etablissement_sante")

# Lire d√©partements depuis Bronze
df_dept = spark.read.parquet("/home/jovyan/data/bronze/csv/departements")

# Extraire code d√©partement
from pyspark.sql.functions import substring

dim_etablissement = df_etab_silver.select(
    col("finess_site").alias("finess"),
    col("siret_site").alias("siret"),
    col("raison_sociale").alias("nom"),
    col("commune").alias("ville"),
    col("code_postal"),
    col("telephone"),
    col("email"),
    substring(col("code_postal"), 1, 2).alias("code_departement")  # ‚Üê AJOUT
).filter(
    col("finess").isNotNull()
).dropDuplicates(["finess"])

# Enrichir avec r√©gion/d√©partement
dim_etablissement = dim_etablissement.join(
    df_dept.select(
        col("num_departement"),
        col("libelle_departement"),
        col("libelle_region"),
        col("abv_region")
    ),
    dim_etablissement["code_departement"] == df_dept["num_departement"],
    "left"
)

print(f"‚úÖ {dim_etablissement.count():,} √©tablissements (enrichis avec r√©gions)")
dim_etablissement.show(5, truncate=False)

dim_etablissement.write \
    .mode("overwrite") \
    .parquet(f"{GOLD_OUTPUT}/dim_etablissement")
```

---

### √âtape 3 : Relancer les notebooks dans l'ordre

```bash
# Dans Jupyter (http://localhost:8888)

# 1. Notebook 01 (avec d√©partements)
# Cell ‚Üí Run All
# R√©sultat attendu : 17 tables (16 + departements)

# 2. Notebook 02 (Silver)
# Cell ‚Üí Run All
# R√©sultat attendu : 12 tables Silver

# 3. Notebook 03 (Gold - MODIFI√â)
# Cell ‚Üí Run All
# R√©sultat attendu :
#   - dim_diagnostic avec 3 colonnes (code_diag, libelle, categorie)
#   - dim_etablissement avec 12 colonnes (+ r√©gion/d√©partement)

# 4. Notebook 04 (Benchmarks)
# Cell ‚Üí Run All
# R√©sultat attendu : Benchmarks sans erreur
```

---

## ‚úÖ R√âSULTAT ATTENDU

### Gold Layer final

| Table | Lignes | Colonnes | Ajouts |
|-------|--------|----------|--------|
| dim_temps | 4,748 | 9 | - |
| dim_patient | 100,000 | 10 | - |
| **dim_diagnostic** | 15,490 | **3** | **+ categorie** ‚úÖ |
| dim_professionnel | 1,048,575 | 5 | - |
| **dim_etablissement** | 416,000 | **12** | **+ r√©gion/d√©partement** ‚úÖ |
| fait_consultation | 1,027,157 | 13 | - |
| fait_deces | 620,625 | 15 | - |
| fait_satisfaction | 8 | 16 | - |

---

## üéØ NOUVELLES ANALYSES POSSIBLES

### 1. Top diagnostics par cat√©gorie

```sql
SELECT
    d.categorie,
    COUNT(*) as nb_consultations
FROM fait_consultation f
JOIN dim_diagnostic d ON f.code_diag = d.code_diag
WHERE d.categorie IS NOT NULL
GROUP BY d.categorie
ORDER BY nb_consultations DESC
```

### 2. Consultations par r√©gion

```sql
SELECT
    e.libelle_region,
    COUNT(*) as nb_consultations
FROM fait_consultation f
JOIN dim_etablissement e ON f.finess = e.finess
GROUP BY e.libelle_region
ORDER BY nb_consultations DESC
```

### 3. Satisfaction par d√©partement

```sql
SELECT
    e.libelle_departement,
    AVG(s.score_global) as score_moyen
FROM fait_satisfaction s
JOIN dim_etablissement e ON s.finess = e.finess
WHERE e.libelle_departement IS NOT NULL
GROUP BY e.libelle_departement
ORDER BY score_moyen DESC
```

---

**Pr√™t √† appliquer les corrections !**
