# üîÑ COMPARAISON : Notre approche vs Code de ton coll√®gue

**Date** : 21 Octobre 2025

---

## üìã TON COLL√àGUE T'A ENVOY√â QUOI ?

Ton coll√®gue t'a envoy√© un script Python qui traite **PostgreSQL** avec un syst√®me de **batching** (d√©coupage en morceaux).

**Son code** :
```python
def process_source_batch(spark, config):
    if source_type == "postgres":
        # Obtenir le nombre total de lignes
        total_rows = get_table_count(spark, source_path)

        if total_rows > BATCH_SIZE:  # BATCH_SIZE = 1M
            # Traiter par batch de 1M lignes
            for batch_num in range(num_batches):
                df_batch = read_postgres_batch(spark, source_path, offset, BATCH_SIZE)
                df_processed = process_dataframe(df_batch, config)
                write_batch_to_minio(df_processed, output_table, batch_num)
```

**Ce que √ßa fait** :
- Lit PostgreSQL par morceaux de 1M lignes
- √âvite de charger toute la table en m√©moire d'un coup
- √âcrit chaque morceau dans MinIO

---

## ‚ùì POURQUOI SON CODE NE S'APPLIQUE PAS √Ä TOI ?

### Diff√©rence 1 : Source de donn√©es

| Ton coll√®gue | Toi |
|--------------|-----|
| Lit **PostgreSQL** (table `deces`) | Lis **CSV** (`deces.csv`) |
| Probl√®me: Table trop grosse en PostgreSQL | Probl√®me: CSV trop gros (25M lignes) |

‚û°Ô∏è **Son code traite PostgreSQL, pas CSV direct !**

---

### Diff√©rence 2 : Approche

**Ton coll√®gue** :
```
CSV ‚Üí PostgreSQL (charg√© avant) ‚Üí Spark (par batch) ‚Üí Bronze
```

**Toi (meilleure approche)** :
```
CSV ‚Üí Spark (direct) ‚Üí Bronze
```

‚û°Ô∏è **Tu lis directement le CSV, pas via PostgreSQL !**

---

## üéØ POURQUOI NOTRE APPROCHE EST MEILLEURE ?

### 1. **Pas besoin de PostgreSQL interm√©diaire**

**Code ton coll√®gue** (2 √©tapes) :
```python
# √âtape 1 : Charger CSV dans PostgreSQL (non montr√© dans son code)
# COPY deces FROM 'deces.csv' ...

# √âtape 2 : Lire PostgreSQL par batch
df_batch = read_postgres_batch(spark, "deces", offset, 1000000)
```

**Notre approche** (1 √©tape) :
```python
# Lecture CSV directe
df = spark.read.csv("deces.csv")
```

‚û°Ô∏è **Pas besoin de PostgreSQL = plus simple et plus rapide**

---

### 2. **Spark g√®re d√©j√† le "batching" automatiquement**

**Code ton coll√®gue** (batching manuel) :
```python
# D√©coupe manuelle en morceaux
for batch_num in range(num_batches):
    offset = batch_num * 1000000
    df_batch = read_postgres_batch(spark, table, offset, 1000000)
```

**Notre approche** (batching automatique Spark) :
```python
# Spark d√©coupe automatiquement en partitions
df = spark.read.csv("deces.csv")
df = df.repartition(20)  # 25M √∑ 20 = 1.25M par partition

# Spark traite chaque partition en parall√®le automatiquement
```

‚û°Ô∏è **Spark fait le batching tout seul = moins de code**

---

### 3. **CSV ‚Üí Parquet plus efficace que PostgreSQL ‚Üí Parquet**

**Code ton coll√®gue** :
```
CSV (3 GB)
  ‚Üí PostgreSQL (index + overhead = 5 GB)
  ‚Üí Spark read JDBC (lent)
  ‚Üí Parquet (300 MB)
```

**Notre approche** :
```
CSV (3 GB)
  ‚Üí Spark read CSV (rapide)
  ‚Üí Parquet (300 MB)
```

‚û°Ô∏è **Moins d'√©tapes = plus rapide**

---

## üìä COMPARAISON D√âTAILL√âE

| Aspect | Code ton coll√®gue | Notre approche |
|--------|-------------------|----------------|
| **Source** | PostgreSQL | CSV direct |
| **√âtape interm√©diaire** | PostgreSQL | Aucune |
| **Batching** | Manuel (boucle for) | Automatique (Spark) |
| **Complexit√©** | ~200 lignes | ~30 lignes |
| **Performance** | Moyenne (JDBC lent) | Rapide (CSV natif) |
| **Gestion m√©moire** | Manuelle | Automatique |
| **Crash risqu√© ?** | Non (batching manuel) | Non (Spark g√®re) |

---

## ü§î QUAND UTILISER L'APPROCHE DE TON COLL√àGUE ?

### ‚úÖ Son code est utile si :

1. **Les donn√©es sont D√âJ√Ä dans PostgreSQL**
   ```
   # Si tu as d√©j√† charg√© deces.csv dans PostgreSQL
   # Et que tu ne peux pas acc√©der au CSV original
   ```

2. **Table PostgreSQL √©norme (100M+ lignes)**
   ```
   # Batching manuel peut aider si Spark gal√®re
   ```

3. **M√©moire tr√®s limit√©e (< 4 GB)**
   ```
   # Batching manuel donne plus de contr√¥le
   ```

---

### ‚ùå Son code N'est PAS utile si :

1. **Tu as acc√®s au CSV original** ‚úÖ (ton cas)
   ```
   # Pourquoi passer par PostgreSQL ?
   ```

2. **Tu as 8 GB+ de m√©moire** ‚úÖ (ton cas)
   ```
   # Spark peut g√©rer 25M lignes sans batching manuel
   ```

3. **Tu veux un pipeline simple** ‚úÖ (ton cas)
   ```
   # Moins de code = moins de bugs
   ```

---

## üöÄ NOTRE SOLUTION FINALE (OPTIMALE)

### Notebook 01 - Cellule 11 (modifi√©e)

```python
# 3. D√âC√àS COMPLET (SANS FILTRAGE - CSV BRUT INT√âGRAL)
df_deces_full = spark.read \
    .option("header", "true") \
    .option("inferSchema", "true") \
    .option("mode", "PERMISSIVE") \
    .csv(f"{DATA_DIR}/DECES EN FRANCE/deces.csv")

# Repartitionner pour optimiser (√©quivalent du batching automatique)
df_deces_full = df_deces_full.repartition(20)

# Ajout m√©tadonn√©es
df_with_meta = df_deces_full \
    .withColumn("ingestion_timestamp", current_timestamp()) \
    .withColumn("ingestion_date", lit(datetime.now().strftime("%Y-%m-%d")))

# Sauvegarde en Bronze (compression automatique)
output_path = f"{OUTPUT_BASE}/csv/deces"
df_with_meta.write \
    .mode("overwrite") \
    .option("compression", "snappy") \
    .parquet(output_path)

print(f"‚úÖ deces COMPLET OK ({row_count:,} lignes)")
```

---

## üéì CE QUE TU RETIENS

### 1. **CSV direct > PostgreSQL interm√©diaire**

```python
# ‚ùå MAUVAIS (2 √©tapes)
CSV ‚Üí PostgreSQL ‚Üí Spark ‚Üí Parquet

# ‚úÖ BON (1 √©tape)
CSV ‚Üí Spark ‚Üí Parquet
```

---

### 2. **Spark g√®re le batching automatiquement**

```python
# ‚ùå MAUVAIS (batching manuel)
for batch in batches:
    df = read_batch(offset, limit)

# ‚úÖ BON (Spark g√®re)
df = spark.read.csv("file.csv")
df = df.repartition(20)  # Spark d√©coupe automatiquement
```

---

### 3. **Bronze = TOUT garder (pas de filtrage)**

```python
# ‚ùå MAUVAIS (filtrage dans Bronze)
df_2019 = df.filter(year(col("date")) == 2019)

# ‚úÖ BON (Bronze brut complet)
df_all = df  # TOUTES les ann√©es
# Filtrage dans Silver/Gold
```

---

### 4. **Optimisations Spark suffisent**

```python
# Configuration d√©j√† optimale :
.config("spark.driver.memory", "8g")               # ‚úÖ
.config("spark.executor.memory", "8g")             # ‚úÖ
.config("spark.sql.adaptive.enabled", "true")      # ‚úÖ
.option("compression", "snappy")                   # ‚úÖ
.repartition(20)                                   # ‚úÖ
```

---

## ‚úÖ R√âSUM√â

### Code de ton coll√®gue :
- ‚úÖ Bon pour PostgreSQL
- ‚úÖ Bon pour batching manuel
- ‚ùå Pas n√©cessaire pour CSV direct
- ‚ùå Plus complexe que n√©cessaire

### Notre approche :
- ‚úÖ CSV direct (pas de PostgreSQL)
- ‚úÖ Batching automatique Spark
- ‚úÖ Plus simple (30 lignes vs 200)
- ‚úÖ Plus rapide (1 √©tape vs 2)
- ‚úÖ Conforme Data Lake

---

**Conclusion** : Ton coll√®gue avait un probl√®me PostgreSQL, toi tu as un probl√®me CSV. **Notre solution est mieux adapt√©e √† ton cas.** ‚úÖ
